1:"$Sreact.fragment"
2:I[7555,[],""]
3:I[1295,[],""]
4:I[6874,["874","static/chunks/874-cc2576bc474eff4b.js","345","static/chunks/app/not-found-fd366f5f6ec9569a.js"],""]
6:I[9665,[],"OutletBoundary"]
9:I[9665,[],"ViewportBoundary"]
b:I[9665,[],"MetadataBoundary"]
d:I[6614,[],""]
:HL["/_next/static/media/569ce4b8f30dc480-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/media/93f479601ee12b01-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/628c91383682af4c.css","style"]
0:{"P":null,"b":"RfHu0hWwfXLvYnVaoPos6","p":"","c":["",""],"i":false,"f":[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/628c91383682af4c.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","children":["$","body",null,{"className":"__variable_5cfdac __variable_9a8899 antialiased","children":["$","$L2",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L3",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","div",null,{"className":"flex flex-col items-center justify-center min-h-screen p-4","children":[["$","h1",null,{"className":"text-4xl font-serif mb-4","children":"404"}],["$","h2",null,{"className":"text-2xl mb-6","children":"Page Not Found"}],["$","p",null,{"className":"mb-8 text-center","children":"The page you are looking for doesn't exist or has been moved."}],["$","$L4",null,{"href":"/","className":"px-6 py-3 border border-neutral-200 hover:bg-primary/10 transition-colors","children":"Return Home"}]]}],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L5","$undefined",null,["$","$L6",null,{"children":["$L7","$L8",null]}]]}],{},null,false]},[["$","div","l",{"className":"flex items-center justify-center min-h-screen","children":["$","div",null,{"className":"animate-spin rounded-full h-12 w-12 border-t-2 border-b-2 border-primary"}]}],[],[]],false],["$","$1","h",{"children":[null,["$","$1","UNdDv6iJ9XK08jZgGadWD",{"children":[["$","$L9",null,{"children":"$La"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],["$","$Lb",null,{"children":"$Lc"}]]}],false]],"m":"$undefined","G":["$d","$undefined"],"s":false,"S":true}
e:I[5784,["874","static/chunks/874-cc2576bc474eff4b.js","852","static/chunks/852-9cedb43e92e50098.js","974","static/chunks/app/page-a966df61ebec5ac5.js"],"default"]
f:I[6372,["874","static/chunks/874-cc2576bc474eff4b.js","852","static/chunks/852-9cedb43e92e50098.js","974","static/chunks/app/page-a966df61ebec5ac5.js"],"LeftSide"]
10:I[2811,["874","static/chunks/874-cc2576bc474eff4b.js","852","static/chunks/852-9cedb43e92e50098.js","974","static/chunks/app/page-a966df61ebec5ac5.js"],"default"]
11:T15f5,<p><em>What if we pushed lyrics through a series of noisy neural language transformations a la a distortion pedal</em></p>
<p><img src="/images/posts/pedal_tinkering_illustration.png" alt="PedalBored Concept"></p>
<p>Guitar pedals transform signals in unpredictable and rewarding ways - could we do the same with lyrics? This idea occurred to me about 6 years ago when implementing a Naive Bayes classifier for text classification during my first computational statistics course. I said I would circle back -- well here I am.</p>
<p>Back.</p>
<p>Now I'm using large-scale transformer architectures instead of simple probabilistic models. And now I can just let Claude Code do simple development tasks in the background while I do laundry etc.</p>
<p><img src="/images/posts/lyric_operator_pedal.png" alt="Lyric Operator Pedal"></p>
<h2>How It Works</h2>
<p><img src="/images/posts/pedalbored_flow_diagram.svg" alt="PedalBored Flow Diagram"></p>
<p><strong>Light Distortion</strong> applies sequential machine translation across multiple target languages. Each language exhibits distinct semantic constraints and syntactic structures, inducing gradual semantic drift with each translation step. Like running audio through a chain of signal processors.</p>
<p><strong>Heavy Distortion</strong> first performs translation to a target language, then applies masked language modeling in that linguistic context, forcing the transformer to perform contextual inference within non-English semantic space. The text then continues through additional translation hops, accumulating both translation artifacts and language-specific idiomatic influences.</p>
<h2>Example 1: Kitchen Light</h2>
<p>A transformer model generated a simple test text exploring themes of domestic transgression</p>
<table>
  <tbody><tr>
    <th>Original</th>
    <th>Light Distortion</th>
    <th>Heavy Distortion</th>
  </tr>
  <tr>
    <td>
      Kitchen light spills yellow into the night<br>
      The freezer door hangs open wide<br>
      These small rebellions I've designed
    </td>
    <td>
      The kitchen is flooded with yellow light at night.<br>
      The door of the freezer has been left open.<br>
      My small act of resistance.
    </td>
    <td>
      The warm yellow glow of the kitchen light.<br>
      The freezer door remains wide open.<br>
      Those foods I have forgotten.
    </td>
  </tr>
</tbody></table>
<p>The semantic drift is evident: "small rebellions I've designed" undergoes lexical formalization to "small act of resistance" (maintaining semantic coherence), then experiences complete conceptual divergence to "foods I have forgotten" (preserving only the spatial context while losing intentionality).</p>
<h2>Example 2: Like a Rolling Stone (Verse 1)</h2>
<p>Dylan's classic opening verse, increasingly scrambled.</p>
<table>
  <tbody><tr>
    <th>Original</th>
    <th>Light Distortion</th>
    <th>Heavy Distortion</th>
  </tr>
  <tr>
    <td>
      Once upon a time you dressed so fine<br>
      Threw the bums a dime in your prime, didn't you?<br>
      ...<br>
      Like a complete unknown, like a rolling stone
    </td>
    <td>
      You used to be very chic, didn't you?<br>
      At the peak of your time, you even threw 10 cents to beggars...<br>
      Like a stranger, like a rolling stone
    </td>
    <td>
      You were once so well dressed<br>
      You gave a ten-franc piece to the beggars...<br>
      Like a boat without a rudder, like a rolling leaf
    </td>
  </tr>
</tbody></table>
<p>My favorite transformation: "like a rolling stone" â†’ "like a boat without a rudder, like a rolling leaf". The cascaded translation process generated novel metaphorical constructions that preserve the semantic essence of directionless motion while introducing a different idiom that has some fresh potential.</p>
<h2>Try It Yourself</h2>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> pedalbored <span class="hljs-keyword">import</span> language_chain, mutate_words_mask, AnthropicTranslator

<span class="hljs-comment"># Light distortion</span>
light = language_chain(
    lyrics=<span class="hljs-string">"Your text here"</span>,
    languages=[<span class="hljs-string">"French"</span>, <span class="hljs-string">"Japanese"</span>, <span class="hljs-string">"German"</span>]
)

<span class="hljs-comment"># Heavy distortion: translate first, then apply masked language modeling in target language</span>
translator = AnthropicTranslator()
french_text = translator.translate(<span class="hljs-string">"Your text here"</span>, <span class="hljs-string">"English"</span>, <span class="hljs-string">"French"</span>)
masked_french = mutate_words_mask(french_text, {<span class="hljs-string">"mask_probability"</span>: <span class="hljs-number">0.6</span>})
heavy = language_chain(
    lyrics=masked_french,
    languages=[<span class="hljs-string">"Japanese"</span>, <span class="hljs-string">"German"</span>],  <span class="hljs-comment"># Continue from French</span>
    translator=translator
)
</code></pre>
<h2>Is This Useful?</h2>
<p>Probably not. But neither are my 4 delay pedals. Sometimes you need your words to undergo a stochastic transformation through some GPUs in Oregon and return <em>semantically altered man</em>. One could optimize the outputs through prompt engineering, translation chain length, masking probability tuning, etc. and generate more compelling lyrical variations than what I've demonstrated.</p>
<p>In any case, I found  I learned quite a bit about these models and the current API (including how to evade copyright violations).</p>
<hr>12:T1896,<p>Inspired by both the need to hire someone and this nice aesthetic for job descriptions from <a href="https://bnext.bio/Synthetic_Cell_Engineer.pdf">b.next</a>, I recently created a minimal LaTeX template for formatting job descriptions. The template hopefully provides a clean, professional, minimalistic layout that someone else could use.</p>
<p><img src="/images/posts/jd_template_preview.png" alt="Job Description Template Preview"></p>
<p>You can view the full template <a href="/assets/pdfs/minimal_JD_PDF_pub.pdf">here</a>.</p>
<h2>Template Structure</h2>
<p>The template is organized into several key sections:</p>
<ol>
<li>Job Title and Basic Information</li>
<li>Position Overview</li>
<li>Key Responsibilities</li>
<li>Required Qualifications</li>
<li>Additional Information (optional)</li>
</ol>
<h2>LaTeX Source</h2>
<p>Here's the minimal LaTeX code to create this template:</p>
<p>{% raw %}</p>
<pre><code class="hljs language-latex">\documentclass[11pt,a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage[dvipsnames]{xcolor}
\usepackage{tikz}
\usepackage{tikzpagenodes}
\usepackage{graphicx}
\usepackage{transparent}

% Define custom beige color
\definecolor{lightbeige}{RGB}{245, 245, 220}

% Set page color and text color
\pagecolor{lightbeige}
\color{black}

% Define custom section style
\titleformat{\section}
  {\Large\bfseries}
  {}
  {0em}
  {}
  []

% Adjust hyperlink color
\hypersetup{
  colorlinks=true,
  linkcolor=black,
  filecolor=black,
  urlcolor=black,
}

% Define the double frame drawing command
\AddToHook{shipout/background}{%
  \begin{tikzpicture}[remember picture,overlay]
    % Outer rectangle
    \draw[black,line width=0.5pt] 
      ([xshift=0.2in,yshift=-0.2in]current page.north west) 
      rectangle 
      ([xshift=-0.2in,yshift=0.2in]current page.south east);
    
    % Inner rectangle
    \draw[black,line width=0.5pt] 
      ([xshift=0.3in,yshift=-0.3in]current page.north west) 
      rectangle 
      ([xshift=-0.3in,yshift=0.3in]current page.south east);
  \end{tikzpicture}%
}

\begin{document}

% Header with line and logo
\begin{tikzpicture}[remember picture,overlay]
  % Black line
  \draw[black, line width=1pt] 
    (current page text area.north west) -- 
    (current page text area.north east);
  
  % Logo placeholder
  \node[anchor=north east, yshift=45pt] at (current page text area.north east) {
    [COMPANY LOGO]
  };
\end{tikzpicture}

\vspace*{0.5in}

% Job Title (aligned to the left margin)
\noindent\textbf{\Large [JOB TITLE]}

\vspace{0.1em}
\noindent\large [LOCATION]

\vspace{0.2em}
\noindent [WORK TYPE] @ [OFFICE LOCATION]

\vspace{2em}

\noindent [COMPANY NAME] is optimizing the synergistic paradigms of cross-functional deliverables through recursive stakeholder engagement. Our mission is to leverage agile methodologies to disrupt old markets while organizing new ones. \newline \newline
\noindent Our leadership team emerged fully-formed from various merger-acquisition events, including:
\begin{itemize}
  \item A former Chief Innovation Officer who pioneered the the LinkedIn engagement bait post where you say something shocking and then heavily qualify it
  \item Three consecutive quarters of record-breaking paradigm shifts as measured by KPIs
  \item Several highly qualified individuals whose roles are described in recursive acronyms
\end{itemize}

\section*{The Role}
As [JOB TITLE], you'll be accountable for driving accountability while ensuring all metrics are properly accounted for. Success in this role requires the ability to simultaneously move both upstream and downstream, while maintaining a lateral trajectory across all verticals. We want you to simultaneously create and destroy frameworks across our technical stack.

\section*{Your Work}
\begin{itemize}
  \item Optimize the efficiency of our optimization protocols
  \item Manage the strategic oversight of strategy implementation
  \item Leverage cross-functional synergies to facilitate greater organization cohesivity
  \item Generate reports about the status of reports about report generation
  \item Maintain KPI performance indicators other metrics which measuring our performance
  \item Facilitate the streamlining of our facilitation processes
  \item Chair the committee on committee efficiency
\end{itemize}

\section*{Who You Are}
\begin{itemize}
  \item Master's degree (or similar experience) in Strategic Strategizing or equivalent years of experience in Factorio
  \item Proven track record of recording tracks and tracking records
  \item Demonstrated ability to circle back on circling back
  \item Expert-level proficiency in taking things offline while remaining online
  \item Strong understanding of understanding strong understandings
  \item Certified in certifying certifications
  \item Results-oriented approach to orienting results toward result orientation
  \item Capable of managing up, down, and sideways simultaneously while remaining perpendicular to objectives
\end{itemize}

\section*{Benefits \&#x26; Perks}
\begin{itemize}
  \item Competitive salary of [SALARY RANGE] subject to quarterly readjustment based on the performance of performance metrics
  \item Health insurance (pending approval from the Committee on Insurance-Related Health Matters)
  \item Unlimited PTRPTO (Permission to Request Permission for Time Off)
  \item Access to our proprietary coffee-to-meeting conversion pipeline
  \item Professional development opportunities to develop professional opportunity development
  \item Ping pong table (pending approval from the Recreational Asset Utilization Oversight Board)
\end{itemize}

\section*{Our Investors \&#x26; Partners}
\begin{itemize}
  \item Various venture capital entities currently undergoing entity verification
  \item Strategic partnerships with partners
  \item Key angels
\end{itemize}

\vspace{1em}
\begin{center}
\textit{Join us in our mission to [COMPANY MISSION STATEMENT] \\
(This posting has been approved by the Department of Posting Approval Approvals)}
\end{center}

\small
\noindent [COMPANY NAME] is an equal opportunity employer, as certified by our Equal Opportunity Employment Opportunity Certification Committee.

\end{document}
</code></pre>
<p>{% endraw %}</p>13:T4a47,<p><img src="/images/posts/dalle_files/firstdisplay.png" alt="png"></p>
<p>I explored the DALL-E 2 model API, in particular the image masking / in-painting functions. Most edits were not artistically compelling, but I find that leveraging simple combinatorial generation allows the creating of a more interesting semi-random collage.</p>
<p>The implementation demonstrates inpainting techniques through masked image editing, where specific spatial regions are reconstructed based on textual conditioning.</p>

<h3>Import Necessary Libaries and Define a Few Helper Functions</h3>
<pre><code class="hljs language-python"><span class="hljs-keyword">import</span> os
<span class="hljs-keyword">import</span> openai
<span class="hljs-keyword">import</span> itertools
<span class="hljs-keyword">import</span> random
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">import</span> uuid
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
openai.api_key =  os.environ[<span class="hljs-string">"OPENAI_API_KEY"</span>]
openai.Model.<span class="hljs-built_in">list</span>()
<span class="hljs-comment"># Functions</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">ask_gpt</span>(<span class="hljs-params">prompt</span>):
    response = openai.Completion.create(
        engine=<span class="hljs-string">"text-davinci-003"</span>,  <span class="hljs-comment"># use the latest model available to you</span>
        prompt=prompt,
        max_tokens=<span class="hljs-number">200</span>, 
    )
    output_text_parsed = response.choices[<span class="hljs-number">0</span>].text.strip()
    <span class="hljs-built_in">print</span>(output_text_parsed)
    <span class="hljs-keyword">return</span> response
<span class="hljs-comment"># make a uniqueish string to label images as they are generated</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_uniqueish_string</span>():
    <span class="hljs-keyword">return</span> <span class="hljs-built_in">str</span>(uuid.uuid4())[:<span class="hljs-number">8</span>]

<span class="hljs-keyword">def</span> <span class="hljs-title function_">process_dalle_images</span>(<span class="hljs-params">response, filename, image_dir, i, <span class="hljs-built_in">hash</span> = <span class="hljs-literal">True</span></span>):
    <span class="hljs-comment"># save the images</span>
    uid = generate_uniqueish_string()
    urls = [datum[<span class="hljs-string">"url"</span>] <span class="hljs-keyword">for</span> datum <span class="hljs-keyword">in</span> response[<span class="hljs-string">"data"</span>]]  <span class="hljs-comment"># extract URLs</span>
    images = [requests.get(url).content <span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> urls]  <span class="hljs-comment"># download images</span>
    image_names = [<span class="hljs-string">f"<span class="hljs-subst">{filename}</span>_<span class="hljs-subst">{i + <span class="hljs-number">1</span>}</span>_<span class="hljs-subst">{uid}</span>.png"</span> <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(images))]  <span class="hljs-comment"># create names</span>
    filepaths = [os.path.join(image_dir, name) <span class="hljs-keyword">for</span> name <span class="hljs-keyword">in</span> image_names]  <span class="hljs-comment"># create filepaths</span>
    <span class="hljs-keyword">for</span> image, filepath <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(images, filepaths):  <span class="hljs-comment"># loop through the variations</span>
        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(filepath, <span class="hljs-string">"wb"</span>) <span class="hljs-keyword">as</span> image_file:  <span class="hljs-comment"># open the file</span>
            image_file.write(image)  <span class="hljs-comment"># write the image to the file</span>

    <span class="hljs-keyword">return</span> filepaths
<span class="hljs-comment"># set a directory to save DALLÂ·E images to</span>
image_dir_name = <span class="hljs-string">"images"</span>
image_dir = os.path.join(os.curdir, image_dir_name)

<span class="hljs-comment"># create the directory if it doesn't yet exist</span>
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.isdir(image_dir):
    os.mkdir(image_dir)

<span class="hljs-comment"># print the directory to save to</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"<span class="hljs-subst">{image_dir=}</span>"</span>)
<span class="hljs-keyword">def</span> <span class="hljs-title function_">top_half_mask</span>(<span class="hljs-params">width, height, mask_dir, mask_name</span>):
    mask = Image.new(<span class="hljs-string">"RGBA"</span>, (width, height), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>))
    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(width):
        <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(height // <span class="hljs-number">2</span>):
            mask.putpixel((x, y), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>))
    mask_filepath = os.path.join(mask_dir, mask_name)
    mask.save(mask_filepath)

<span class="hljs-keyword">def</span> <span class="hljs-title function_">bottom_half_mask</span>(<span class="hljs-params">width, height, mask_dir, mask_name</span>):
    mask = Image.new(<span class="hljs-string">"RGBA"</span>, (width, height), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>))
    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(width):
        <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(height // <span class="hljs-number">2</span>, height):
            mask.putpixel((x, y), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>))
    mask_filepath = os.path.join(mask_dir, mask_name)
    mask.save(mask_filepath)

<span class="hljs-keyword">def</span> <span class="hljs-title function_">left_half_mask</span>(<span class="hljs-params">width, height, mask_dir, mask_name</span>):
    mask = Image.new(<span class="hljs-string">"RGBA"</span>, (width, height), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>))
    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(width // <span class="hljs-number">2</span>):
        <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(height):
            mask.putpixel((x, y), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>))
    mask_filepath = os.path.join(mask_dir, mask_name)
    mask.save(mask_filepath)

<span class="hljs-keyword">def</span> <span class="hljs-title function_">right_half_mask</span>(<span class="hljs-params">width, height, mask_dir, mask_name</span>):
    mask = Image.new(<span class="hljs-string">"RGBA"</span>, (width, height), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>))
    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(width // <span class="hljs-number">2</span>, width):
        <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(height):
            mask.putpixel((x, y), (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>))
    mask_filepath = os.path.join(mask_dir, mask_name)
    mask.save(mask_filepath)

</code></pre>
<pre><code>image_dir='./images'
</code></pre>
<h3>Show Image we are working with</h3>
<pre><code class="hljs language-python">american_gothic = <span class="hljs-string">"images/American_Gothic_Square.png"</span>
im = Image.<span class="hljs-built_in">open</span>(american_gothic)
display(im)
</code></pre>
<p><img src="/images/posts/dalle_files/dalle_3_0.png" alt="png"></p>
<h3>Leverage Large Language Models for Style Prompt Generation</h3>
<pre><code class="hljs language-python"><span class="hljs-comment"># Prompt engineering for art style enumeration via autoregressive language modeling</span>
question = <span class="hljs-string">"provide a python list of 15 distinct art styles (i.e. impressionist, cubist, pointlist, photorealistic, japanese wood block print)"</span>
<span class="hljs-comment"># Join the description and question into a single string</span>
prompt = <span class="hljs-string">f"<span class="hljs-subst">{question}</span>"</span>
gpt_output = ask_gpt(prompt)
<span class="hljs-comment"># Parse the output</span>
art_styles_string = gpt_output.choices[<span class="hljs-number">0</span>][<span class="hljs-string">'text'</span>]
art_styles = [line.split(<span class="hljs-string">'. '</span>)[<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> art_styles_string.split(<span class="hljs-string">'\n'</span>) <span class="hljs-keyword">if</span> line]
<span class="hljs-comment"># choose the length of combinations you want, for example 2</span>
length_of_combinations = <span class="hljs-number">2</span>
style_combinations = <span class="hljs-built_in">list</span>(itertools.combinations(art_styles, length_of_combinations))
</code></pre>
<pre><code>1. Impressionism 
2. Cubism 
3. Pointillism 
4. Photorealism 
5. Japanese Wood Block Print 
6. Expressionism 
7. Constructivism 
8. Abstract Expressionism 
9. Surrealism 
10. Baroque 
11. Realism 
12. Neo-Impressionism 
13. Art Deco 
14. Cubo-Futurism 
15. Op Art
</code></pre>
<pre><code class="hljs language-python"><span class="hljs-comment"># Format the GPT output for Dalle prompt</span>
formatted_strings = []

<span class="hljs-keyword">for</span> combination <span class="hljs-keyword">in</span> style_combinations:
    style_1, style_2 = combination
    formatted_string = <span class="hljs-string">f"in the style of <span class="hljs-subst">{style_1}</span> and <span class="hljs-subst">{style_2}</span>"</span>
    formatted_strings.append(formatted_string)
<span class="hljs-comment"># TODO would be better to print at random from the list to actually show</span>
<span class="hljs-keyword">for</span> string <span class="hljs-keyword">in</span> formatted_strings[:<span class="hljs-number">10</span>]:
    <span class="hljs-built_in">print</span>(string)

</code></pre>
<pre><code>in the style of Impressionism  and Cubism .
in the style of Impressionism  and Pointillism .
in the style of Pointillism  and Surrealism .
in the style of Cubism  and Baroque .
</code></pre>
<h3>Create Masks</h3>
<pre><code class="hljs language-python">mask_dir = <span class="hljs-string">"images/masks"</span>
<span class="hljs-comment"># create the directory if it doesn't yet exist</span>
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.isdir(mask_dir):
    os.mkdir(mask_dir)
<span class="hljs-comment"># print the directory to save to</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"<span class="hljs-subst">{mask_dir=}</span>"</span>)

<span class="hljs-comment"># TODO ask what are the actual image sizes </span>
width = <span class="hljs-number">574</span>
height = <span class="hljs-number">574</span>

mask_dir = <span class="hljs-string">"./masks"</span>
os.makedirs(mask_dir, exist_ok=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># ensure the directory exists</span>
top_half_mask(width, height, mask_dir, <span class="hljs-string">"top_half_mask.png"</span>)
bottom_half_mask(width, height, mask_dir, <span class="hljs-string">"bottom_half_mask.png"</span>)
left_half_mask(width, height, mask_dir, <span class="hljs-string">"left_half_mask.png"</span>)
right_half_mask(width, height, mask_dir, <span class="hljs-string">"right_half_mask.png"</span>)

<span class="hljs-comment"># specify edit images dir</span>
edit_image_dir = os.path.join(<span class="hljs-string">"images"</span>, <span class="hljs-string">"edits"</span>)
</code></pre>
<pre><code>mask_dir='images/masks'
</code></pre>
<pre><code class="hljs language-python">os.makedirs(<span class="hljs-string">f"<span class="hljs-subst">{edit_image_dir}</span>"</span>, exist_ok=<span class="hljs-literal">True</span>)
</code></pre>
<h3>Execute DALL-E 2 Inpainting with Stochastic Mask Selection and Style Conditioning</h3>
<pre><code class="hljs language-python"><span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> implement metadata embedding for tracking conditioning parameters in generated samples</span>

<span class="hljs-comment"># Specify the directory</span>
mask_dir = <span class="hljs-string">"./masks/"</span>
num_iterations = <span class="hljs-number">4</span>  <span class="hljs-comment"># specify the number of iterations</span>

<span class="hljs-comment"># Get the list of all masks in the directory</span>
masks = [f <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> os.listdir(mask_dir) <span class="hljs-keyword">if</span> f.endswith(<span class="hljs-string">'.png'</span>)]

<span class="hljs-comment"># Iterate for the number of specified iterations</span>
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_iterations):
    <span class="hljs-comment"># Select a random mask</span>
    selected_mask = random.choice(masks)
    <span class="hljs-comment"># Get the full file path of the selected mask</span>
    mask_filepath = os.path.join(mask_dir, selected_mask)

    <span class="hljs-comment"># Select a random style combination</span>
    selected_prompt = random.choice(formatted_strings)

    <span class="hljs-comment"># Execute conditional image generation via masked inpainting</span>
    edit_response = openai.Image.create_edit(
        image=<span class="hljs-built_in">open</span>(american_gothic, <span class="hljs-string">"rb"</span>),  <span class="hljs-comment"># source image for conditioning</span>
        mask=<span class="hljs-built_in">open</span>(mask_filepath, <span class="hljs-string">"rb"</span>),  <span class="hljs-comment"># spatial mask for inpainting region</span>
        prompt=selected_prompt,  <span class="hljs-comment"># textual conditioning for style transfer</span>
        n=<span class="hljs-number">1</span>,  <span class="hljs-comment"># number of samples from posterior distribution</span>
        size=<span class="hljs-string">"512x512"</span>,  <span class="hljs-comment"># output resolution</span>
        response_format=<span class="hljs-string">"url"</span>,
    )
    
    <span class="hljs-comment"># print response for prototype / debug</span>
    <span class="hljs-comment"># print(edit_response)</span>
    edit_filepaths = process_dalle_images(edit_response, <span class="hljs-string">"edits"</span>, edit_image_dir, i, <span class="hljs-built_in">hash</span> = <span class="hljs-literal">True</span>)

</code></pre>
<h3>Visualization of Generated Sample Distribution via Grid Assembly</h3>
<pre><code class="hljs language-python"><span class="hljs-comment"># Specify the directory</span>
image_directory = <span class="hljs-string">"images/edits/"</span>
image_files = [f <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> os.listdir(image_directory) <span class="hljs-keyword">if</span> f.endswith(<span class="hljs-string">'.png'</span>)]
<span class="hljs-comment"># shuffle image file order to get different images in the plot</span>
image_files = np.random.permutation(image_files)
<span class="hljs-comment"># Load all the images</span>
images = [Image.<span class="hljs-built_in">open</span>(image_directory + f) <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> image_files]
<span class="hljs-comment"># Ensure sufficient samples for statistical visualization through repetition</span>
<span class="hljs-keyword">while</span> <span class="hljs-built_in">len</span>(images) &#x3C; <span class="hljs-number">100</span>:
    images *= <span class="hljs-number">2</span>

<span class="hljs-comment"># Only take the first 100 images</span>
images = images[:<span class="hljs-number">100</span>]

<span class="hljs-comment"># Create a 10x10 visualization grid for sample distribution analysis</span>
fig, axes = plt.subplots(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>, figsize=(<span class="hljs-number">18</span>, <span class="hljs-number">18</span>))

<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):
    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):
        <span class="hljs-comment"># Get the image</span>
        img = images[i * <span class="hljs-number">10</span> + j]

        <span class="hljs-comment"># Remove the axes for each subplot</span>
        axes[i, j].axis(<span class="hljs-string">'off'</span>)

        <span class="hljs-comment"># Display the image on the subplot</span>
        axes[i, j].imshow(np.array(img), aspect=<span class="hljs-string">'auto'</span>)

<span class="hljs-comment"># Adjust the space between the subplots</span>
<span class="hljs-comment"># Negative values for wspace and hspace will make the images overlap</span>
plt.subplots_adjust(wspace=-<span class="hljs-number">0.05</span>, hspace=-<span class="hljs-number">0.05</span>)

<span class="hljs-comment"># Show the plot</span>
plt.show()
</code></pre>
<p><img src="/images/posts/dalle_files/dalle_13_0.png" alt="png"></p>14:T2581,<p><img src="/images/posts/llm_antibody/llm_ir-writeup_38_0.png" alt="png"></p>
<p>I investigated the application of protein language models (PLMs) for immunoglobulin sequence analysis. Antibodies are adaptive immune proteins critical for pathogen neutralization. This study integrates B-cell receptor (BCR) sequencing data, AbLang (an antibody-specific protein language model), and single-cell RNA sequencing to explore computational approaches in immunoinformatics.</p>

<h3>Protein Language Models in Structural Biology</h3>
<p>Protein language models leverage transformer architectures adapted from natural language processing to analyze amino acid sequences. These models undergo unsupervised pre-training on large-scale protein databases, learning evolutionary constraints and structural motifs encoded in sequence space. Through self-attention mechanisms, they capture long-range amino acid dependencies critical for protein folding and function. The learned representations encode biophysical properties including secondary structure, solvent accessibility, and functional domains. I investigated their application to immunoglobulin evolution and somatic hypermutation analysis.</p>
<h3>AbLang: Antibody-Specific Protein Language Model</h3>
<p><img src="/images/posts/llm_antibody/llm_ir-writeup_7_0.jpg" alt="jpeg"></p>
<p>AbLang is a domain-specific protein language model trained exclusively on immunoglobulin sequences, optimizing representations for antibody variable regions. While domain-specific models may capture immunoglobulin-specific evolutionary patterns, comparative analysis with general protein language models (e.g., ESM-2, ProtTrans) would provide valuable benchmarking for immunoinformatics applications.</p>
<h3>Additional Background about Antibodies at the bottom:</h3>
<p>Somatic hypermutation frequency serves as a molecular marker of affinity maturation, with higher mutation loads indicating extensive germinal center selection and clonal evolution from naive B-cell precursors.</p>
<h2>Overview of my investigation:</h2>
<ul>
<li>integrate single-cell transcriptomic profiles with AbLang-derived immunoglobulin embeddings</li>
<li>apply principal component analysis to protein language model representations</li>
<li>perform unsupervised clustering of immunoglobulin sequence embeddings</li>
<li>conduct differential gene expression analysis using embedding-defined B-cell subpopulations</li>
<li>generate low-dimensional visualizations via UMAP projection</li>
</ul>
<h2>Protein Language Models for Immunoglobulin Analysis in Single-Cell Genomics</h2>
<p>A Quick Look at the Dataset</p>
<p><img src="/images/posts/llm_antibody/llm_ir-writeup_18_0.png" alt="png"></p>
<p>The dataset comprises hundreds to thousands of individual B cells per sample, each with paired single-cell transcriptomic profiles and cognate immunoglobulin heavy and light chain sequences.</p>
<p>These UMAP projections demonstrate global coherence between transcriptomic states and immunoglobulin sequence characteristics:</p>
<ol>
<li>UMAP projections of single-cell transcriptomic data colored by B-cell developmental state (left) and immunoglobulin sequence features (right panels)</li>
<li>Memory B cells represent antigen-experienced populations with accumulated somatic hypermutations, while naive B cells maintain germline immunoglobulin sequences</li>
<li>Mutation frequency is quantified as nucleotide divergence from inferred germline V(D)J gene segments</li>
<li>Memory B cells exhibit class switch recombination from IgM to downstream isotypes (IgG, IgA, IgE), indicating germinal center participation</li>
</ol>
<p><img src="/images/posts/llm_antibody/llm_ir-writeup_21_1.png" alt="png"></p>
<p>Immunoglobulin sequence annotations demonstrate strong concordance with transcriptomically-defined B-cell subsets. Memory B cells predominantly harbor hypermutated immunoglobulin sequences, confirming the molecular signatures of germinal center-derived populations.</p>
<p>I investigated whether protein language model embeddings capture biologically meaningful immunoglobulin features including somatic hypermutation and isotype usage. The following PCA analysis examines these categorical variables within AbLang embedding space:</p>
<p><img src="/images/posts/llm_antibody/llm_ir-writeup_26_0.png" alt="png"></p>
<p>The protein language model demonstrates learned representations of somatic hypermutation, cleanly separating germline from hypermutated immunoglobulins along PC1 and PC3. PC3 reveals continuous variation within hypermutated sequence space, with a clear trajectory from IgM to class-switched isotypes (IgG, IgA). This suggests the model captures fundamental immunoglobulin biology including affinity maturation and class switch recombination.</p>
<p>Quantitative analysis of somatic hypermutation along principal components, particularly PC3 which separates IgM from class-switched isotypes, reveals corresponding patterns in transcriptomic space:</p>
<p><img src="/images/posts/llm_antibody/llm_ir-writeup_29_1.png" alt="png"></p>
<p>As an aside, we can see a fair amount of "no mutation" antibody sequences (highighted in the red box or seen in the tail of the orange distribtion) that actually appear more like mutated antibodies in the PC space. I asked if the gene expression of cells with that profile looked like Memory B cells, which would corroborate that the antibody actually is hypermutated. Indeed these cells with "no mutations" appear to have a memory-like phenotype, suggesting the language model identifies mutations in antibodies more sensitively than how I orginally labeled the mutation status, via comparison to a genomic database.</p>
<p>I noticed from some exploratory plots that the while the distribution of hypermutated antibodies on PC3 doesn't appear to have any notable features, if I subset different cell types, multiple modes appear. For example, hypermutated Memory B cells appear to have multple two modes in PC3</p>
<p><img src="/images/posts/llm_antibody/llm_ir-writeup_32_1.png" alt="png"></p>
<p>I split the hypermutated Memory B cells at 1 in PC3 space and asked if there were gene expression differences between the groups</p>
<p><img src="/images/posts/llm_antibody/llm_ir-writeup_35_1.png" alt="png"></p>
<p>Indeed there are clear differences, with PC3 low having a IGHM memory phenotype and PC3 high  deeper or class-switched memory phenotype</p>
<p>Let's finally take a quick look at the UMAP projection of the antibody sequence encodings</p>
<p><img src="/images/posts/llm_antibody/llm_ir-writeup_38_0.png" alt="png"></p>
<p><img src="/images/posts/llm_antibody/llm_ir-writeup_38_1.png" alt="png"></p>
<p>UMAP projection demonstrates clustering by V gene family usage alongside somatic hypermutation levels. Immunoglobulin sequences cluster by germline V gene origin, with secondary separation of hypermutated variants within each gene family, reflecting both germline diversity and somatic evolution.</p>
<h3>Summary:</h3>
<p>This immunoinformatics analysis demonstrates that protein language models capture biologically relevant immunoglobulin features:</p>
<ul>
<li>AbLang embeddings encode somatic hypermutation along orthogonal dimensions</li>
<li>Binary germline vs. hypermutated classification along one axis</li>
<li>Continuous mutation load quantification along another axis</li>
<li>Embedding-based immunoglobulin clustering correlates with independent transcriptomic B-cell phenotypes</li>
</ul>
<h3>Future Directions:</h3>
<ul>
<li>Quantify embedding space distances for clonally related immunoglobulins to assess phylogenetic signal preservation</li>
<li>Develop cross-species protein language models incorporating mouse, camelid, and non-human primate immunoglobulin data for comparative immunogenomics</li>
<li>Train memory-specific models exclusively on hypermutated sequences to enhance affinity maturation signal detection</li>
</ul>
<h3>Immunoglobulin Structure and Function</h3>
<p>Immunoglobulins are tetrameric glycoproteins comprising two heavy chains and two light chains linked by disulfide bonds in a characteristic Y-shaped quaternary structure. The antigen-binding domain, formed by the variable heavy (VH) and variable light (VL) regions, determines specificity through complementarity-determining regions (CDRs) that contact cognate antigens.</p>
<p>The variable region is generated stochastically through a process called V(D)J recombination. This process involves the pseudo-random selection, recombination, and joining of gene segmentsâ€”Variable (V), Diversity (D), and Joining (J) segmentsâ€”along with the introduction of pseudo-random nucleotide insertions and deletions between the recombined genes. This generates astromomical standing antibody sequence diversity which could never be encoded in the genome. Selection of particular antibodies from this diversity allows indivuduals to adapt their immune system to never-before-seen pathogens.</p>
<h3>Antibody Evolution</h3>
<p>The antibody generation process creates a large pool standing diversity in protein space. Next, the immune system uses an evolutionary process to select and amplify the antibodies which have the most beneficial properties, such as strongly binding and neutralizing a pathogen which is wreaking havoc in your body. During the selection process, additional diversity is generated by mutating the selected antibodies, allowing the immune system iterate on creating an even better protein: it selects the best of the selected. This process is called somatic hypermuation, and it's pretty much fascinating.</p>5:["$","main",null,{"className":"min-h-screen bg-background","children":["$","$Le",null,{"leftSide":["$","$Lf",null,{"aboutContent":{"slug":"about","content":"<p><strong>Currently</strong>\nI'm a systems biologist using ML to design better RNA therapeutics.</p>\n<p>I earned my PhD at Stanford in the Quake lab, where I studied the generation and maintenance of diversity in the human immune system.</p>\n<p><strong>Some other interests:</strong></p>\n<p>sequencing everything</p>\n<p>sculpting biomes using gene drives</p>\n<p>producing music</p>","title":"","date":"$undefined","excerpt":"About me","category":"$undefined","tags":"$undefined","permalink":"/","author_profile":true,"redirect_from":["/about/","/about.html"]}}],"rightSide":["$","$L10",null,{"posts":[{"slug":"2025-06-14-pedalbored","content":"$11","title":"PedalBored: Distorting Lyrics Like Guitar Pedals Distort Sound","date":"$D2025-06-14T00:00:00.000Z","excerpt":"neural language transformations to lyrics like guitar pedals transform sound","category":"$undefined","tags":["transformer-models","semantic-drift","lyrical-analysis","computational-linguistics","machine-translation","python"],"layout":"post","image":"/images/posts/pedal_tinkering_illustration.png","categories":["natural-language-processing","computational-creativity","music-informatics"]},{"slug":"2024-11-19-minimal-latex-job-description-template","content":"$12","title":"A Minimal LaTeX Job Description Template","date":"$D2024-11-19T00:00:00.000Z","excerpt":"a clean, professional LaTeX template for creating job description PDF","category":"$undefined","tags":["latex","job-description","template","documentation"],"layout":"post","image":"/images/posts/jd_template_preview.png","categories":["latex","templates"]},{"slug":"2023-10-24-cover_letter","content":"<p><img src=\"/images/posts/latex/manuscript_submission_cover_letter_overleaf.png\" alt=\"png\"></p>\n<p>I was writing a cover letter for a journal submission and got tired of manually formatting everything each time. So I made a LaTeX template to automate the process. It handles all the standard formatting and lets you just fill in the details.</p>\n\n<p>The template takes care of the layout, spacing, and professional formatting automatically. You just need to update a few variables at the top of the document with your information and the journal details, and it generates a properly formatted cover letter.</p>\n<p>I've put it up on <a href=\"https://github.com/michael-swift/JournalCoverLetter\">GitHub</a> and made it available as a template on <a href=\"https://www.overleaf.com/latex/templates/journal-submission-cover-letter/vsvmwwszmdtn\">Overleaf</a> so anyone can use it.</p>","title":"Cover Letter LaTeX Template","date":"$D2023-11-20T00:00:00.000Z","excerpt":"a clean LaTeX template for academic journal submission cover letters","category":"$undefined","tags":["document-generation","typesetting-systems","manuscript-preparation","template-engineering","scholarly-communication"],"permalink":"/posts/2023/10/cover_letter","categories":["Document-Automation","Academic-Publishing"],"header":{"og_image":"/images/posts/latex/manuscript_submission_cover_letter_overleaf.png"}},{"slug":"2023-05-24-dalle","content":"$13","title":"DALL-E and a Combinatoric Collage","date":"$D2023-05-26T00:00:00.000Z","excerpt":"generative image model collages","category":"$undefined","tags":["computer-vision","generative-modeling","multimodal-ai","image-synthesis","diffusion-models","neural-networks","deep-learning"],"permalink":"/posts/2023/05/dalle","excerpt_separator":"<!--more-->","always_allow_html":true,"toc":true,"header":{"og_image":"/images/posts/dalle_files/dalle_3_0.png"},"categories":["computer-vision","generative-ai"]},{"slug":"2023-03-04-antibodies","content":"$14","title":"Protein Language Models for Immunoglobulin Sequence Analysis","date":"$D2023-03-04T00:00:00.000Z","excerpt":"Do protein language models capture meaningful features of antibody sequences?","category":"$undefined","tags":["protein-language-models","computational-biology","immunoinformatics","single-cell-transcriptomics","antibody-repertoire","somatic-hypermutation","immunoglobulin-analysis"],"permalink":"/posts/2023/05/nest-map","excerpt_separator":"<!--more-->","always_allow_html":true,"toc":true,"header":{"og_image":"/images/posts/llm_antibody/llm_ir-writeup_38_0.png"}}],"scienceProjects":[{"slug":"project-1","content":"<img src=\"/images/tabula_bursa_schematic.png\" alt=\"Tabula Bursa Schematic\">\n<p>By sampling B cells from multiple hard-to-study organs within the same individual, Ivana Cvijovic and I generated the first systems-level perspective of the human antibody system. Most immune-monitoring efforts focus on the peripheral blood because it is non-invasive. Our study compares as many as 5 organs per donor, which allows systematic insights into the dynamics of long-term antibody memory in Humans and informs non-invasive immune monitoring.</p>\n<p>Key findings:</p>\n<ul>\n<li>Long-term antibody memory emerges uniformly throughout the immune response</li>\n<li>Proliferative antibody-secreting cells uniquely circulate among multiple tissues</li>\n<li>Immune-monitoring via the peripheral blood has key sampling biases and limitations</li>\n</ul>\n<p><a href=\"https://www.biorxiv.org/content/10.1101/2023.11.27.568934v1.full.pdf\">Read the full paper</a></p>","title":"Mapping the Statistics of the Human B cell system","date":"2025","excerpt":"A systems-level view of B cells by sampling multiple hard-to-study organs within the same individual.","category":"Systems Biology","tags":"$undefined","image":"/tabula_bursa_schematic.png","link":"https://www.pnas.org/doi/10.1073/pnas.2406474122","collection":"science"},{"slug":"project-2","content":"<img src=\"/images/bcell_schematic.png\" alt=\"B Cell Schematic\">\n<p>This study investigates how cells integrate external signals with their intrinsic state during reprogramming, using human B cells as a model system.</p>\n<p>Key findings:</p>\n<ul>\n<li>Intrinsic cellular states significantly influence reprogramming outcomes</li>\n<li>Reprogrammed cell populations show high diversity in final states</li>\n<li>Cells from the same lineage (clones) often adopt similar fates, indicating the importance of initial cell state</li>\n</ul>\n<img src=\"/images/lineage_tracing_measurement.png\" alt=\"Lineage Graph\">\n<p>These results have important implications for cell-based therapies and tissue engineering. Intrinsic heterogeneity in the input cells should be understood and harnessed for better outcomes.</p>\n<p><a href=\"https://www.life-science-alliance.org/content/lsa/6/3/e202201792.full.pdf\">Read the full paper</a> | <a href=\"https://doi.org/10.6084/m9.figshare.26348788\">Download processed data</a></p>","title":"Leveraging lineage tracing to understand cell reprogramming","date":"2023","excerpt":"How cells integrate external signals with their intrinsic state during reprogramming, using human B cells as a model system.","category":"Cell Biology","tags":"$undefined","image":"/images/phd_defense_screenshot.png","link":"https://www.life-science-alliance.org/content/lsa/6/3/e202201792.full.pdf","collection":"science"},{"slug":"project-3","content":"<img src=\"/images/reduced_ts_figure.png\" alt=\"Reduced TS Figure\">\n<p>I have been key contributor to the Tabula Sapiens Consortium. I helped create a multi-organ, single-cell transcriptomic atlas of humans. This atlas serves as a valuable resource for training foundation models of biology and understanding the molecular basis of diseases.</p>\n<p>My contributions include:</p>\n<ul>\n<li>Procuring organs</li>\n<li>Processing tissues into single-cell suspensions</li>\n<li>Preparing sequencing libraries</li>\n<li>Analyzing vast datasets with complex and varied forms of technical noise</li>\n</ul>\n<p>Research focus:\nAnalyzing immune cells across tissues to gain new insights into this complex system's function and regulation within the context of the broader human atlas.</p>\n<p><a href=\"https://www.science.org/doi/10.1126/science.abl4896\">Read the full paper</a></p>","title":"Creating the datasets to enable Molecular Medicine","date":"2022","excerpt":"Key contributor to the Tabula Sapiens Consortium. Massive single-cell molecular datasets enabling foundation models and molecular medicine.","category":"Single Cell Transcriptomics","tags":"$undefined","image":"/images/reduced_ts_figure.png","link":"https://tabula-sapiens.sf.czbiohub.org/","collection":"science"},{"slug":"sequencing","content":"<ul>\n<li><a href=\"https://aseq.substack.com/\">A-seq</a> - sequencing technologies and associated approaches including diagnositics and tools</li>\n<li><a href=\"https://biotechbio.substack.com/\">BiotechBio</a> - someone at the forefront of AI and Bio</li>\n<li><a href=\"https://substack.com/@billyhb\">Billy's Newsletter</a> - cool guy</li>\n<li><a href=\"https://www.nxn.se/\">NxN</a> - great for single cell rna seq amongst other topics</li>\n<li><a href=\"https://www.owlposting.com/\">Owl Posting</a> - ML / Bio posting</li>\n</ul>","title":"","date":"$undefined","excerpt":"Some good blogs I've stumbled across over the years","category":"$undefined","tags":"$undefined","disable_link":true,"collection":"science","layout":"single"}],"coverImages":[{"src":"/covers/3d_IgG1.png","alt":"3d IgG1","width":1920,"height":1080},{"src":"/covers/96_well_technical.png","alt":"96 Well Technical","width":1920,"height":1080},{"src":"/covers/RibbonModel-crJaneRichardson-Lede-2048x1152.webp","alt":"RibbonModel CrJaneRichardson Lede 2048x1152","width":1920,"height":1080},{"src":"/covers/Waddingtons-1957-depiction-of-his-epigenetic-landscape-reprinted-with-permission.png","alt":"Waddingtons 1957 Depiction Of His Epigenetic Landscape Reprinted With Permission","width":1920,"height":1080},{"src":"/covers/clepsine.png","alt":"Clepsine","width":1920,"height":1080},{"src":"/covers/yamanaka_factors_stylized.png","alt":"Yamanaka Factors Stylized","width":1920,"height":1080}]}]}]}]
a:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
7:null
8:null
c:[["$","title","0",{"children":"Michael Swift"}],["$","meta","1",{"name":"description","content":"Founding Research Scientist @ Kerna Labs"}],["$","link","2",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"128x128"}]]
