<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/569ce4b8f30dc480-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/93f479601ee12b01-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/e13ea093f033e8dd.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-db3214c5c58110e1.js"/><script src="/_next/static/chunks/4bd1b696-81f15ab42338ecb3.js" async=""></script><script src="/_next/static/chunks/684-fb9c80a8ab173acb.js" async=""></script><script src="/_next/static/chunks/main-app-bc653c44f386db2b.js" async=""></script><script src="/_next/static/chunks/874-900774ead0b7e3c7.js" async=""></script><script src="/_next/static/chunks/app/not-found-fd366f5f6ec9569a.js" async=""></script><script src="/_next/static/chunks/690-bd8484d5d492afd1.js" async=""></script><script src="/_next/static/chunks/app/page-8b9a5f513f9ac8ba.js" async=""></script><meta name="next-size-adjust" content=""/><title>Michael Swift</title><meta name="description" content="Founding Research Scientist @ Kerna Labs"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__variable_5cfdac __variable_9a8899 antialiased"><!--$--><main class="min-h-screen bg-background"><div class="flex flex-col md:flex-row min-h-screen"><div class="min-h-screen md:min-h-0 md:w-2/5 md:fixed md:h-screen md:top-0 md:left-0 md:border-r-2 md:border-neutral-200 bg-background"><div class="min-h-screen md:h-full flex flex-col justify-between p-6 md:p-16 lg:p-20"><div class="flex-1 flex flex-col justify-center space-y-4 md:space-y-6 md:block"><div class="transition-opacity duration-500 opacity-100"><div class="mb-6"><h1 class="text-3xl md:text-4xl font-sans font-medium"><a class="hover:underline underline-offset-4 transition-all" href="/">Michael Swift</a></h1></div></div><div class="transition-all duration-500 space-y-4 opacity-0 -translate-y-4 pointer-events-none"><div class="space-y-6"><div class="space-y-6"><div class="space-y-3"><h3 class="text-lg md:text-xl font-serif font-semibold text-foreground">Currently</h3><div class="space-y-4 text-lg md:text-xl font-serif leading-relaxed text-muted-foreground"><p>I&#x27;m a systems biologist using machine learning to design better RNA therapeutics.</p><p>I earned my PhD at Stanford in the Quake lab, where I studied the generation and maintenance of diversity in the human immune system.</p></div></div><div class="w-full h-px bg-neutral-200"></div><div class="space-y-3"><h3 class="text-lg font-serif font-semibold text-foreground">Some other interests</h3><div class="space-y-2 text-base md:text-lg font-serif text-muted-foreground"><div class="flex items-start space-x-2"><span class="text-foreground">•</span><a class="hover:underline underline-offset-4 transition-all" href="/science/sequencing"><span>sequencing everything</span></a></div><div class="flex items-start space-x-2"><span class="text-foreground">•</span><span>other stuff</span></div><div class="flex items-start space-x-2"><span class="text-foreground">•</span><a class="hover:underline underline-offset-4 transition-all" href="/tangents/maiklo"><span>producing music</span></a></div></div></div></div></div><div class="mt-6 w-full h-px bg-neutral-200"></div><div class="mt-6 flex flex-col md:flex-row md:items-start md:justify-between gap-6"><nav class=""><ul class="flex flex-col space-y-2"><li><a class="text-sm transition-colors hover:text-primary flex items-center gap-1 group text-muted-foreground" href="#science"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right w-3 h-3 opacity-0 group-hover:opacity-100 transition-opacity" aria-hidden="true"><path d="m9 18 6-6-6-6"></path></svg><span class="group-hover:underline underline-offset-2">science</span></a></li><li><a class="text-sm transition-colors hover:text-primary flex items-center gap-1 group text-muted-foreground" href="#posts"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right w-3 h-3 opacity-0 group-hover:opacity-100 transition-opacity" aria-hidden="true"><path d="m9 18 6-6-6-6"></path></svg><span class="group-hover:underline underline-offset-2">posts</span></a></li><li><a class="text-sm transition-colors hover:text-primary flex items-center gap-1 group text-muted-foreground" href="/tangents"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right w-3 h-3 opacity-0 group-hover:opacity-100 transition-opacity" aria-hidden="true"><path d="m9 18 6-6-6-6"></path></svg><span class="group-hover:underline underline-offset-2">tangents</span></a></li></ul></nav><div class="md:ml-16"><h4 class="text-sm font-medium mb-2">social</h4><div class="flex space-x-4"><a class="text-neutral-700 hover:text-primary transition-colors" aria-label="Email" href="mailto:swiftmichael26@gmail.com"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mail" aria-hidden="true"><path d="m22 7-8.991 5.727a2 2 0 0 1-2.009 0L2 7"></path><rect x="2" y="4" width="20" height="16" rx="2"></rect></svg></a><a target="_blank" rel="noopener noreferrer" class="text-neutral-700 hover:text-primary transition-colors" aria-label="Google Scholar" href="https://scholar.google.com/citations?hl=en&amp;user=7Ywb2akAAAAJ"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-graduation-cap" aria-hidden="true"><path d="M21.42 10.922a1 1 0 0 0-.019-1.838L12.83 5.18a2 2 0 0 0-1.66 0L2.6 9.08a1 1 0 0 0 0 1.832l8.57 3.908a2 2 0 0 0 1.66 0z"></path><path d="M22 10v6"></path><path d="M6 12.5V16a6 3 0 0 0 12 0v-3.5"></path></svg></a><a target="_blank" rel="noopener noreferrer" class="text-neutral-700 hover:text-primary transition-colors" aria-label="GitHub" href="https://github.com/michael-swift"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github" aria-hidden="true"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a></div></div></div></div></div><div class="md:hidden text-center mt-auto pb-8"><p class="text-sm text-muted-foreground mb-2">Scroll for projects</p><button class="bg-transparent border-none cursor-pointer animate-bounce"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down" aria-hidden="true"><path d="m6 9 6 6 6-6"></path></svg></button></div></div></div><div class="w-full md:w-3/5 md:ml-[40%]"><div class="min-h-screen"><div class="relative h-[60vh] md:h-[780px]"><div class="absolute inset-0 flex items-center justify-center p-8"></div><div class="absolute bottom-8 left-1/2 -translate-x-1/2"><button class="bg-transparent border-none cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-down" aria-hidden="true"><path d="m6 9 6 6 6-6"></path></svg></button></div></div><section id="science" class="p-6 md:p-10 pt-12 md:pt-6"><h2 class="text-3xl font-serif text-center mt-6 mb-4">Science</h2><p class="text-center mb-8">Research projects in computational biology and immunology.</p><div class="space-y-6 max-w-full md:max-w-[90%] mx-auto"><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl py-6 shadow-sm border border-neutral-200"><div data-slot="card-content" class="p-3 border-x border-b border-neutral-200"><div class="text-sm uppercase mb-1">Systems Biology</div><div data-slot="card-title" class="font-semibold text-xl mb-1">Mapping the Statistics of the Human B cell system</div><div class="text-sm mb-2">2025</div><div class="text-base mb-2 prose prose-sm max-w-none text-justify [&amp;_img]:mx-auto [&amp;_img]:block [&amp;_img]:max-w-full">A systems-level view of B cells by sampling multiple hard-to-study organs within the same individual.</div></div><div data-slot="card-footer" class="[.border-t]:pt-6 p-3 border-x border-b border-neutral-200 flex justify-between items-center"><a href="https://www.pnas.org/doi/10.1073/pnas.2406474122" target="_blank" rel="noopener noreferrer" class="transition-all hover:font-bold">Read the Paper</a><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right" aria-hidden="true"><path d="m9 18 6-6-6-6"></path></svg></div></div><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl py-6 shadow-sm border border-neutral-200"><div data-slot="card-content" class="p-3 border-x border-b border-neutral-200"><div class="text-sm uppercase mb-1">Cell Biology</div><div data-slot="card-title" class="font-semibold text-xl mb-1">Leveraging lineage tracing to understand cell reprogramming</div><div class="text-sm mb-2">2023</div><div class="text-base mb-2 prose prose-sm max-w-none text-justify [&amp;_img]:mx-auto [&amp;_img]:block [&amp;_img]:max-w-full">How cells integrate external signals with their intrinsic state during reprogramming, using human B cells as a model system.</div></div><div data-slot="card-footer" class="[.border-t]:pt-6 p-3 border-x border-b border-neutral-200 flex justify-between items-center"><a href="https://www.life-science-alliance.org/content/lsa/6/3/e202201792.full.pdf" target="_blank" rel="noopener noreferrer" class="transition-all hover:font-bold">Read the Paper</a><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right" aria-hidden="true"><path d="m9 18 6-6-6-6"></path></svg></div></div><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl py-6 shadow-sm border border-neutral-200"><div data-slot="card-content" class="p-3 border-x border-b border-neutral-200"><div class="text-sm uppercase mb-1">Single Cell Transcriptomics</div><div data-slot="card-title" class="font-semibold text-xl mb-1">Creating the datasets to enable Molecular Medicine</div><div class="text-sm mb-2">2022</div><div class="text-base mb-2 prose prose-sm max-w-none text-justify [&amp;_img]:mx-auto [&amp;_img]:block [&amp;_img]:max-w-full">I have been a key contributor to the Tabula Sapiens Consortium. Massive single-cell molecular datasets like this have been instrumental cell modeling efforts.</div></div><div data-slot="card-footer" class="[.border-t]:pt-6 p-3 border-x border-b border-neutral-200 flex justify-between items-center"><a href="https://tabula-sapiens.sf.czbiohub.org/" target="_blank" rel="noopener noreferrer" class="transition-all hover:font-bold">Read the Paper</a><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right" aria-hidden="true"><path d="m9 18 6-6-6-6"></path></svg></div></div></div></section><section id="posts" class="p-6 md:p-10"><h2 class="text-3xl font-serif text-center mt-6 mb-4">Posts</h2><p class="text-center mb-8">partially formed ideas and partially implemented projects.</p><div class="space-y-6 max-w-full md:max-w-[90%] mx-auto"><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl py-6 shadow-sm border border-neutral-200 hover:shadow-md transition-shadow"><a href="/posts/2025-06-14-pedalbored" class="block"><div data-slot="card-content" class="p-3 border-x border-b border-neutral-200"><div class="text-sm uppercase mb-1">natural-language-processing</div><div data-slot="card-title" class="font-semibold text-xl mb-2 hover:text-primary transition-colors">PedalBored: Distorting Lyrics Like Guitar Pedals Distort Sound</div><div class="text-sm mb-1">June 14, 2025</div><div class="text-base prose prose-sm max-w-none text-justify [&amp;_img]:mx-auto [&amp;_img]:block [&amp;_img]:max-w-full"><p><em>What if we applied cascaded neural language transformations to lyrics like a distortion pedal modifies audio signals?</em></p>
<p><img src="/images/posts/pedal_tinkering_illustration.png" alt="PedalBored Concept"></p>
<p>Guitar pedals transform signals in unpredictable and rewarding ways - could we do the same with lyrics? This idea occurred to me about 6 years ago when implementing a Naive...</div></div><div data-slot="card-footer" class="[.border-t]:pt-6 p-3 border-x border-b border-neutral-200 flex justify-between items-center"><span class="transition-all hover:font-bold">Read Post</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right" aria-hidden="true"><path d="m9 18 6-6-6-6"></path></svg></div></a></div><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl py-6 shadow-sm border border-neutral-200 hover:shadow-md transition-shadow"><a href="/posts/2024-11-19-minimal-latex-job-description-template" class="block"><div data-slot="card-content" class="p-3 border-x border-b border-neutral-200"><div class="text-sm uppercase mb-1">latex</div><div data-slot="card-title" class="font-semibold text-xl mb-2 hover:text-primary transition-colors">A Minimal LaTeX Job Description Template</div><div class="text-sm mb-1">November 19, 2024</div><div class="text-base prose prose-sm max-w-none text-justify [&amp;_img]:mx-auto [&amp;_img]:block [&amp;_img]:max-w-full"><p>Inspired by both the need to hire someone and this nice aesthetic for job descriptions from <a href="https://bnext.bio/Synthetic_Cell_Engineer.pdf">b.next</a>, I recently created a minimal LaTeX template for formatting job descriptions. The template hopefully provides a clean, professional, minimalistic layout that someone else could use.</p>
<p><img src="/images/posts/jd_template_preview.png" ...</div></div><div data-slot="card-footer" class="[.border-t]:pt-6 p-3 border-x border-b border-neutral-200 flex justify-between items-center"><span class="transition-all hover:font-bold">Read Post</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right" aria-hidden="true"><path d="m9 18 6-6-6-6"></path></svg></div></a></div><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl py-6 shadow-sm border border-neutral-200 hover:shadow-md transition-shadow"><a href="/posts/2024-03-11-rna-obelisks" class="block"><div data-slot="card-content" class="p-3 border-x border-b border-neutral-200"><div class="text-sm uppercase mb-1">Post</div><div data-slot="card-title" class="font-semibold text-xl mb-2 hover:text-primary transition-colors">RNA Obelisks</div><div class="text-sm mb-1">March 11, 2024</div><div class="text-base prose prose-sm max-w-none text-justify [&amp;_img]:mx-auto [&amp;_img]:block [&amp;_img]:max-w-full"><h2>Novel viroid-like entities revealed by computational genomics and bioinformatics</h2>
<p>These authors <em>would</em> write this paper, and I mean that in the good way. We have Andy Fire, who is famous for a deeply thoughtful career in RNA molecular biology and post-transcriptional gene regulation. We have Ami Bhatt: a world-class researcher who leads a group specializing in microbiome genomic...</div></div><div data-slot="card-footer" class="[.border-t]:pt-6 p-3 border-x border-b border-neutral-200 flex justify-between items-center"><span class="transition-all hover:font-bold">Read Post</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right" aria-hidden="true"><path d="m9 18 6-6-6-6"></path></svg></div></a></div><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl py-6 shadow-sm border border-neutral-200 hover:shadow-md transition-shadow"><a href="/posts/2023-10-24-cover_letter" class="block"><div data-slot="card-content" class="p-3 border-x border-b border-neutral-200"><div class="text-sm uppercase mb-1">Document-Automation</div><div data-slot="card-title" class="font-semibold text-xl mb-2 hover:text-primary transition-colors">Cover Letter LaTeX Template</div><div class="text-sm mb-1">November 20, 2023</div><div class="text-base prose prose-sm max-w-none text-justify [&amp;_img]:mx-auto [&amp;_img]:block [&amp;_img]:max-w-full"><p><img src="/images/posts/latex/manuscript_submission_cover_letter_overleaf.png" alt="png"></p>
<p>I was writing a cover letter for a journal submission and got tired of manually formatting everything each time. So I made a LaTeX template to automate the process. It handles all the standard formatting and lets you just fill in the details.</p>

<p>The template takes care of the layout, spacing, a...</div></div><div data-slot="card-footer" class="[.border-t]:pt-6 p-3 border-x border-b border-neutral-200 flex justify-between items-center"><span class="transition-all hover:font-bold">Read Post</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right" aria-hidden="true"><path d="m9 18 6-6-6-6"></path></svg></div></a></div><div data-slot="card" class="bg-card text-card-foreground flex flex-col gap-6 rounded-xl py-6 shadow-sm border border-neutral-200 hover:shadow-md transition-shadow"><a href="/posts/2023-05-24-dalle" class="block"><div data-slot="card-content" class="p-3 border-x border-b border-neutral-200"><div class="text-sm uppercase mb-1">computer-vision</div><div data-slot="card-title" class="font-semibold text-xl mb-2 hover:text-primary transition-colors">DALL-E and a Combinatoric Collage: Generative Image Models</div><div class="text-sm mb-1">May 26, 2023</div><div class="text-base prose prose-sm max-w-none text-justify [&amp;_img]:mx-auto [&amp;_img]:block [&amp;_img]:max-w-full"><p><img src="/images/posts/dalle_files/firstdisplay.png" alt="png"></p>
<p>I wanted to explore the DALL-E 2 diffusion model API along with combinatorial generation algorithms and visualization techniques to create a semi-random collage of latent space manipulations of American Gothic. This experiment involved leveraging both the DALL-E 2 image synthesis capabilities and the GPT-3 language model fo...</div></div><div data-slot="card-footer" class="[.border-t]:pt-6 p-3 border-x border-b border-neutral-200 flex justify-between items-center"><span class="transition-all hover:font-bold">Read Post</span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right" aria-hidden="true"><path d="m9 18 6-6-6-6"></path></svg></div></a></div></div></section></div></div></div></main><!--/$--><script src="/_next/static/chunks/webpack-db3214c5c58110e1.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7555,[],\"\"]\n3:I[1295,[],\"\"]\n4:I[6874,[\"874\",\"static/chunks/874-900774ead0b7e3c7.js\",\"345\",\"static/chunks/app/not-found-fd366f5f6ec9569a.js\"],\"\"]\n6:I[9665,[],\"OutletBoundary\"]\n9:I[9665,[],\"ViewportBoundary\"]\nb:I[9665,[],\"MetadataBoundary\"]\nd:I[6614,[],\"\"]\n:HL[\"/_next/static/media/569ce4b8f30dc480-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/93f479601ee12b01-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/e13ea093f033e8dd.css\",\"style\"]\n0:{\"P\":null,\"b\":\"KQrV4a42MHYyXSazK-V3y\",\"p\":\"\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/e13ea093f033e8dd.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[\"$\",\"body\",null,{\"className\":\"__variable_5cfdac __variable_9a8899 antialiased\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"div\",null,{\"className\":\"flex flex-col items-center justify-center min-h-screen p-4\",\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-4xl font-serif mb-4\",\"children\":\"404\"}],[\"$\",\"h2\",null,{\"className\":\"text-2xl mb-6\",\"children\":\"Page Not Found\"}],[\"$\",\"p\",null,{\"className\":\"mb-8 text-center\",\"children\":\"The page you are looking for doesn't exist or has been moved.\"}],[\"$\",\"$L4\",null,{\"href\":\"/\",\"className\":\"px-6 py-3 border border-neutral-200 hover:bg-primary/10 transition-colors\",\"children\":\"Return Home\"}]]}],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L5\",\"$undefined\",null,[\"$\",\"$L6\",null,{\"children\":[\"$L7\",\"$L8\",null]}]]}],{},null,false]},[[\"$\",\"div\",\"l\",{\"className\":\"flex items-center justify-center min-h-screen\",\"children\":[\"$\",\"div\","])</script><script>self.__next_f.push([1,"null,{\"className\":\"animate-spin rounded-full h-12 w-12 border-t-2 border-b-2 border-primary\"}]}],[],[]],false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"TI5XMDsTcahCY7jmHgOST\",{\"children\":[[\"$\",\"$L9\",null,{\"children\":\"$La\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$d\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"e:I[5784,[\"874\",\"static/chunks/874-900774ead0b7e3c7.js\",\"690\",\"static/chunks/690-bd8484d5d492afd1.js\",\"974\",\"static/chunks/app/page-8b9a5f513f9ac8ba.js\"],\"default\"]\nf:I[9732,[\"874\",\"static/chunks/874-900774ead0b7e3c7.js\",\"690\",\"static/chunks/690-bd8484d5d492afd1.js\",\"974\",\"static/chunks/app/page-8b9a5f513f9ac8ba.js\"],\"LeftSide\"]\n10:I[777,[\"874\",\"static/chunks/874-900774ead0b7e3c7.js\",\"690\",\"static/chunks/690-bd8484d5d492afd1.js\",\"974\",\"static/chunks/app/page-8b9a5f513f9ac8ba.js\"],\"default\"]\n11:T1648,"])</script><script>self.__next_f.push([1,"\u003cp\u003e\u003cem\u003eWhat if we applied cascaded neural language transformations to lyrics like a distortion pedal modifies audio signals?\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/posts/pedal_tinkering_illustration.png\" alt=\"PedalBored Concept\"\u003e\u003c/p\u003e\n\u003cp\u003eGuitar pedals transform signals in unpredictable and rewarding ways - could we do the same with lyrics? This idea occurred to me about 6 years ago when implementing a Naive Bayes classifier for text classification during my first computational statistics course. I said I would circle back -- well here. the fuck. I am.\u003c/p\u003e\n\u003cp\u003eBack.\u003c/p\u003e\n\u003cp\u003eExcept now I'm leveraging large-scale transformer architectures instead of simple probabilistic models. And now with Claude Code I can just do things.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/posts/lyric_operator_pedal.png\" alt=\"Lyric Operator Pedal\"\u003e\u003c/p\u003e\n\u003ch2\u003eHow It Works\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/posts/pedalbored_flow_diagram.svg\" alt=\"PedalBored Flow Diagram\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLight Distortion\u003c/strong\u003e applies sequential machine translation across multiple target languages. Each language exhibits distinct semantic constraints and syntactic structures, inducing gradual semantic drift with each translation step. Like running audio through a chain of signal processors.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eHeavy Distortion\u003c/strong\u003e first performs translation to a target language, then applies masked language modeling in that linguistic context, forcing the transformer to perform contextual inference within non-English semantic space. The text then continues through additional translation hops, accumulating both translation artifacts and language-specific idiomatic influences.\u003c/p\u003e\n\u003ch2\u003eExample 1: Kitchen Light\u003c/h2\u003e\n\u003cp\u003eA transformer model generated a simple test text exploring themes of domestic transgression\u003c/p\u003e\n\u003ctable\u003e\n  \u003ctbody\u003e\u003ctr\u003e\n    \u003cth\u003eOriginal\u003c/th\u003e\n    \u003cth\u003eLight Distortion\u003c/th\u003e\n    \u003cth\u003eHeavy Distortion\u003c/th\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\n      Kitchen light spills yellow into the night\u003cbr\u003e\n      The freezer door hangs open wide\u003cbr\u003e\n      These small rebellions I've designed\n    \u003c/td\u003e\n    \u003ctd\u003e\n      The kitchen is flooded with yellow light at night.\u003cbr\u003e\n      The door of the freezer has been left open.\u003cbr\u003e\n      My small act of resistance.\n    \u003c/td\u003e\n    \u003ctd\u003e\n      The warm yellow glow of the kitchen light.\u003cbr\u003e\n      The freezer door remains wide open.\u003cbr\u003e\n      Those foods I have forgotten.\n    \u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003eThe semantic drift is evident: \"small rebellions I've designed\" undergoes lexical formalization to \"small act of resistance\" (maintaining semantic coherence), then experiences complete conceptual divergence to \"foods I have forgotten\" (preserving only the spatial context while losing intentionality).\u003c/p\u003e\n\u003ch2\u003eExample 2: Like a Rolling Stone (Verse 1)\u003c/h2\u003e\n\u003cp\u003eDylan's classic opening verse, increasingly scrambled.\u003c/p\u003e\n\u003ctable\u003e\n  \u003ctbody\u003e\u003ctr\u003e\n    \u003cth\u003eOriginal\u003c/th\u003e\n    \u003cth\u003eLight Distortion\u003c/th\u003e\n    \u003cth\u003eHeavy Distortion\u003c/th\u003e\n  \u003c/tr\u003e\n  \u003ctr\u003e\n    \u003ctd\u003e\n      Once upon a time you dressed so fine\u003cbr\u003e\n      Threw the bums a dime in your prime, didn't you?\u003cbr\u003e\n      ...\u003cbr\u003e\n      Like a complete unknown, like a rolling stone\n    \u003c/td\u003e\n    \u003ctd\u003e\n      You used to be very chic, didn't you?\u003cbr\u003e\n      At the peak of your time, you even threw 10 cents to beggars...\u003cbr\u003e\n      Like a stranger, like a rolling stone\n    \u003c/td\u003e\n    \u003ctd\u003e\n      You were once so well dressed\u003cbr\u003e\n      You gave a ten-franc piece to the beggars...\u003cbr\u003e\n      Like a boat without a rudder, like a rolling leaf\n    \u003c/td\u003e\n  \u003c/tr\u003e\n\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003eMy favorite transformation: \"like a rolling stone\" → \"like a boat without a rudder, like a rolling leaf\". The cascaded translation process generated novel metaphorical constructions that preserve the semantic essence of directionless motion while introducing maritime and botanical imagery.\u003c/p\u003e\n\u003ch2\u003eTry It Yourself\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e pedalbored \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e language_chain, mutate_words_mask, AnthropicTranslator\n\n\u003cspan class=\"hljs-comment\"\u003e# Light distortion\u003c/span\u003e\nlight = language_chain(\n    lyrics=\u003cspan class=\"hljs-string\"\u003e\"Your text here\"\u003c/span\u003e,\n    languages=[\u003cspan class=\"hljs-string\"\u003e\"French\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"Japanese\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"German\"\u003c/span\u003e]\n)\n\n\u003cspan class=\"hljs-comment\"\u003e# Heavy distortion: translate first, then apply masked language modeling in target language\u003c/span\u003e\ntranslator = AnthropicTranslator()\nfrench_text = translator.translate(\u003cspan class=\"hljs-string\"\u003e\"Your text here\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"English\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"French\"\u003c/span\u003e)\nmasked_french = mutate_words_mask(french_text, {\u003cspan class=\"hljs-string\"\u003e\"mask_probability\"\u003c/span\u003e: \u003cspan class=\"hljs-number\"\u003e0.6\u003c/span\u003e})\nheavy = language_chain(\n    lyrics=masked_french,\n    languages=[\u003cspan class=\"hljs-string\"\u003e\"Japanese\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"German\"\u003c/span\u003e],  \u003cspan class=\"hljs-comment\"\u003e# Continue from French\u003c/span\u003e\n    translator=translator\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eIs This Useful?\u003c/h2\u003e\n\u003cp\u003eProbably not in any utilitarian sense. But neither are my 4 delay pedals. Sometimes you need your words to undergo stochastic transformation and return semantically altered. I imagine one could optimize this through prompt engineering, translation chain length, masking probability tuning, etc. and generate more compelling lyrical variations than what I've demonstrated. Maybe if some young computational artist looking to break into the music industry picked up on this approach they could really innovate.\u003c/p\u003e\n\u003cp\u003eOr maybe I just wanted to name something \"PedalBored.\"\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003e\u003cem\u003ePedalBored is open source. Turn the knobs, see what happens.\u003c/em\u003e\u003c/p\u003e"])</script><script>self.__next_f.push([1,"12:T1896,"])</script><script>self.__next_f.push([1,"\u003cp\u003eInspired by both the need to hire someone and this nice aesthetic for job descriptions from \u003ca href=\"https://bnext.bio/Synthetic_Cell_Engineer.pdf\"\u003eb.next\u003c/a\u003e, I recently created a minimal LaTeX template for formatting job descriptions. The template hopefully provides a clean, professional, minimalistic layout that someone else could use.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/posts/jd_template_preview.png\" alt=\"Job Description Template Preview\"\u003e\u003c/p\u003e\n\u003cp\u003eYou can view the full template \u003ca href=\"/assets/pdfs/minimal_JD_PDF_pub.pdf\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003ch2\u003eTemplate Structure\u003c/h2\u003e\n\u003cp\u003eThe template is organized into several key sections:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eJob Title and Basic Information\u003c/li\u003e\n\u003cli\u003ePosition Overview\u003c/li\u003e\n\u003cli\u003eKey Responsibilities\u003c/li\u003e\n\u003cli\u003eRequired Qualifications\u003c/li\u003e\n\u003cli\u003eAdditional Information (optional)\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003eLaTeX Source\u003c/h2\u003e\n\u003cp\u003eHere's the minimal LaTeX code to create this template:\u003c/p\u003e\n\u003cp\u003e{% raw %}\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-latex\"\u003e\\documentclass[11pt,a4paper]{article}\n\\usepackage[margin=1in]{geometry}\n\\usepackage{titlesec}\n\\usepackage{enumitem}\n\\usepackage{hyperref}\n\\usepackage[dvipsnames]{xcolor}\n\\usepackage{tikz}\n\\usepackage{tikzpagenodes}\n\\usepackage{graphicx}\n\\usepackage{transparent}\n\n% Define custom beige color\n\\definecolor{lightbeige}{RGB}{245, 245, 220}\n\n% Set page color and text color\n\\pagecolor{lightbeige}\n\\color{black}\n\n% Define custom section style\n\\titleformat{\\section}\n  {\\Large\\bfseries}\n  {}\n  {0em}\n  {}\n  []\n\n% Adjust hyperlink color\n\\hypersetup{\n  colorlinks=true,\n  linkcolor=black,\n  filecolor=black,\n  urlcolor=black,\n}\n\n% Define the double frame drawing command\n\\AddToHook{shipout/background}{%\n  \\begin{tikzpicture}[remember picture,overlay]\n    % Outer rectangle\n    \\draw[black,line width=0.5pt] \n      ([xshift=0.2in,yshift=-0.2in]current page.north west) \n      rectangle \n      ([xshift=-0.2in,yshift=0.2in]current page.south east);\n    \n    % Inner rectangle\n    \\draw[black,line width=0.5pt] \n      ([xshift=0.3in,yshift=-0.3in]current page.north west) \n      rectangle \n      ([xshift=-0.3in,yshift=0.3in]current page.south east);\n  \\end{tikzpicture}%\n}\n\n\\begin{document}\n\n% Header with line and logo\n\\begin{tikzpicture}[remember picture,overlay]\n  % Black line\n  \\draw[black, line width=1pt] \n    (current page text area.north west) -- \n    (current page text area.north east);\n  \n  % Logo placeholder\n  \\node[anchor=north east, yshift=45pt] at (current page text area.north east) {\n    [COMPANY LOGO]\n  };\n\\end{tikzpicture}\n\n\\vspace*{0.5in}\n\n% Job Title (aligned to the left margin)\n\\noindent\\textbf{\\Large [JOB TITLE]}\n\n\\vspace{0.1em}\n\\noindent\\large [LOCATION]\n\n\\vspace{0.2em}\n\\noindent [WORK TYPE] @ [OFFICE LOCATION]\n\n\\vspace{2em}\n\n\\noindent [COMPANY NAME] is optimizing the synergistic paradigms of cross-functional deliverables through recursive stakeholder engagement. Our mission is to leverage agile methodologies to disrupt old markets while organizing new ones. \\newline \\newline\n\\noindent Our leadership team emerged fully-formed from various merger-acquisition events, including:\n\\begin{itemize}\n  \\item A former Chief Innovation Officer who pioneered the the LinkedIn engagement bait post where you say something shocking and then heavily qualify it\n  \\item Three consecutive quarters of record-breaking paradigm shifts as measured by KPIs\n  \\item Several highly qualified individuals whose roles are described in recursive acronyms\n\\end{itemize}\n\n\\section*{The Role}\nAs [JOB TITLE], you'll be accountable for driving accountability while ensuring all metrics are properly accounted for. Success in this role requires the ability to simultaneously move both upstream and downstream, while maintaining a lateral trajectory across all verticals. We want you to simultaneously create and destroy frameworks across our technical stack.\n\n\\section*{Your Work}\n\\begin{itemize}\n  \\item Optimize the efficiency of our optimization protocols\n  \\item Manage the strategic oversight of strategy implementation\n  \\item Leverage cross-functional synergies to facilitate greater organization cohesivity\n  \\item Generate reports about the status of reports about report generation\n  \\item Maintain KPI performance indicators other metrics which measuring our performance\n  \\item Facilitate the streamlining of our facilitation processes\n  \\item Chair the committee on committee efficiency\n\\end{itemize}\n\n\\section*{Who You Are}\n\\begin{itemize}\n  \\item Master's degree (or similar experience) in Strategic Strategizing or equivalent years of experience in Factorio\n  \\item Proven track record of recording tracks and tracking records\n  \\item Demonstrated ability to circle back on circling back\n  \\item Expert-level proficiency in taking things offline while remaining online\n  \\item Strong understanding of understanding strong understandings\n  \\item Certified in certifying certifications\n  \\item Results-oriented approach to orienting results toward result orientation\n  \\item Capable of managing up, down, and sideways simultaneously while remaining perpendicular to objectives\n\\end{itemize}\n\n\\section*{Benefits \\\u0026#x26; Perks}\n\\begin{itemize}\n  \\item Competitive salary of [SALARY RANGE] subject to quarterly readjustment based on the performance of performance metrics\n  \\item Health insurance (pending approval from the Committee on Insurance-Related Health Matters)\n  \\item Unlimited PTRPTO (Permission to Request Permission for Time Off)\n  \\item Access to our proprietary coffee-to-meeting conversion pipeline\n  \\item Professional development opportunities to develop professional opportunity development\n  \\item Ping pong table (pending approval from the Recreational Asset Utilization Oversight Board)\n\\end{itemize}\n\n\\section*{Our Investors \\\u0026#x26; Partners}\n\\begin{itemize}\n  \\item Various venture capital entities currently undergoing entity verification\n  \\item Strategic partnerships with partners\n  \\item Key angels\n\\end{itemize}\n\n\\vspace{1em}\n\\begin{center}\n\\textit{Join us in our mission to [COMPANY MISSION STATEMENT] \\\\\n(This posting has been approved by the Department of Posting Approval Approvals)}\n\\end{center}\n\n\\small\n\\noindent [COMPANY NAME] is an equal opportunity employer, as certified by our Equal Opportunity Employment Opportunity Certification Committee.\n\n\\end{document}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e{% endraw %}\u003c/p\u003e"])</script><script>self.__next_f.push([1,"13:T242a,"])</script><script>self.__next_f.push([1,"\u003ch2\u003eNovel viroid-like entities revealed by computational genomics and bioinformatics\u003c/h2\u003e\n\u003cp\u003eThese authors \u003cem\u003ewould\u003c/em\u003e write this paper, and I mean that in the good way. We have Andy Fire, who is famous for a deeply thoughtful career in RNA molecular biology and post-transcriptional gene regulation. We have Ami Bhatt: a world-class researcher who leads a group specializing in microbiome genomics and metagenomic analysis. We also have the participation of Robert C. Edgar on the paper — he is, as far as I am aware, the only “independent researcher” in biology that is respected. His open-source bioinformatics software MUSCLE is integral to many phylogenetic reconstructions. Plus I like his style:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd57360b0-bebf-43f2-a9e8-e97efb39c9f2_1698x940.png\"\u003e\u003cimg src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd57360b0-bebf-43f2-a9e8-e97efb39c9f2_1698x940.png\" alt=\"\"\u003e\u003c/a\u003ethis is the platonic case of a dude who got rich by selling a tech company in the late 90s\u003c/p\u003e\n\n\u003ch4\u003e\u003cstrong\u003eSo what’s a viroid?\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eIt is like a virus, but even simpler. Viruses are obligate intracellular parasites carrying minimal genomic content required for replication. This typically includes RNA-dependent RNA polymerases (RdRp) or DNA polymerases for genome replication and structural proteins forming the capsid. Viral polymerases serve as phylogenetic markers for taxonomic classification through sequence homology analyses. Of course, if you’re a freeloading parasite already, why not freeload harder and just use your host’s polymerase and also it’s warm inside cells so get rid of that protein coat. To me, seems like a winning strategy. Yet this strategy would make traditional approaches for detecting viroid-like entities difficult, because they don’t have much sequence similarity to anything else. And they don’t have much sequence at all really.\u003c/p\u003e\n\u003ch4\u003eViroid nominator\u003c/h4\u003e\n\u003cp\u003eThe authors developed Vnom, a computational pipeline employing heuristic algorithms to identify putative viroid-like elements. Candidate sequences must exhibit circular topology and bidirectional strand detection, indicating active replication through complementary strand synthesis.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0341e07-442e-4654-9485-2ef98701b95d_1570x442.png\"\u003e\u003cimg src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc0341e07-442e-4654-9485-2ef98701b95d_1570x442.png\" alt=\"\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThe authors note:\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eWhile these filters should enrich for viroid-like RNAs, highly repetitive sequences also satisfy these requirements and so are often also enriched. VNom was found to work adequately well on deeply sequenced viroid-positive plant RNA-seq datasets (e.g. SRR11060618, SRR11060619, SRR11060620, and SRR16133646), especially when assemblies from the same bioProject were grouped together.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eAs a reader, I would be curious to understand more about the outputs of this algorithm. Is there any way to estimate the specificity or sensitivity? Obviously the ground-truth isn’t known, but even downsampling the plant RNA-seq datasets mentioned would be interesting. Additionally, even a heavily caveated analysis of the outputs would be welcome. How many outputs appear to be highly repetitive, how many have ORFs, what is the homology of these ORFs to other proteins?\u003c/p\u003e\n\u003ch4\u003eObelisk-like RNA structure and donor variability:\u003c/h4\u003e\n\u003cp\u003eThe authors predict the RNA secondary structure of these entities and find them to be highly “rod-like” or “obelisk-y” as seen in \u003cstrong\u003eb\u003c/strong\u003e and \u003cstrong\u003ec\u003c/strong\u003e. Figure c is a chord plot where the red lines denote predicted based pairing. I’ve never really found these plots useful in other areas of genomics, but this one does give a pretty good sense of the RNA structure. Figure \u003cstrong\u003ed\u003c/strong\u003e below is interesting as it shows within donor variability in Obelisk RNA read counts. The temporal stability of these entities within donors is clear. The abundance of in donor A is shocking to me — at ~190 days around 1/5000 reads belong to map to Obelisks.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F570ed51e-25aa-41fd-a189-e7506e62e357_900x660.png\"\u003e\u003cimg src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F570ed51e-25aa-41fd-a189-e7506e62e357_900x660.png\" alt=\"\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003eWhat does the RNA make?\u003c/h2\u003e\n\u003cp\u003eOn the protein side, the authors make structural predictions of the Oblin-1 coding regions using AlphaFold. The globular folds for many of the representatives (Figure 4 tertiary structures) hint at potential RNA binding or chaperone functions (worth validating experimentally). Certainly \u003ca href=\"https://saulkato.medium.com/genomics-and-ai-then-what-e998ccbdd684\"\u003eexperimental work is necessary\u003c/a\u003e, but the high degree of structural conservation despite sequence divergence points to an real function for these proteins. We can only speculate, but perhaps they are kinetically helpful for co-opting host transcriptional machinery.\u003c/p\u003e\n\u003cp\u003eThe proposed phylogeny (Figure 3a) is messy, and Robert would be the first to tell you it can be \u003ca href=\"https://www.youtube.com/watch?v=2HmjHStpu7I\"\u003equite tricky\u003c/a\u003e to estimate correct phylogenetic topologies. The authors' suggest new phylogenetic approaches that integrate RNA structure and protein folding with MSA could prove powerful not just for Obelisks but other structured RNAs as well. It is an interesting idea, people often incorporate some priors about models of what mutations are likely to occur, but I’ve only really seen it in the context of a biochemical model of how mutations occur. Regardless of the topology of the phylogeny, it is clear these RNA entities are all over the globe, which is cool.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ba1001-ee1a-4871-a9c8-a6ed60670b1e_746x890.png\"\u003e\u003cimg src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ba1001-ee1a-4871-a9c8-a6ed60670b1e_746x890.png\" alt=\"\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003ch3\u003eAre they CRISPy?\u003c/h3\u003e\n\u003cp\u003eThe authors checked if any Obelisks have been captured by CRISPR systems, which may indicate hostile interactions with prokaryotic hosts. Using a database of nearly 30 million CRISPR spacers, they ran a conservative k-mer matching search. Out of around 39,000 Obelisk sequences examined, only one measly spacer mapped to a putative \"Obelisk-gamma\" contig over 1000 nts long. Seems this spacer comes from the alphaprotebacterium Bombella mellum. But Obelisk-gamma looks kinda wonky - deviating from that classic rod-like structure with some unpaired, frayed ends. The author’s remain equivocal about whether this is some type of computational artefact or a real CRISPR hit.\u003c/p\u003e\n\u003cp\u003eGiven caveats about the sensitivity of sequence similarity search, I'm not ruling out that CRISPR system occasionally snag an Obelisk. And I’m not sure we’d be surprised not to find them anyways. There’s some math about their prevalence plus how many spacers are in the database and whether the database is biased in some way. However, their absence raises an interesting question of whether these RNAs have a special ability able to evade the prokaryotic immune system effectively .. or maybe they aren’t deletrious enough to merit mounting an immune response against.\u003c/p\u003e\n\u003ch3\u003eDiscussion\u003c/h3\u003e\n\u003cp\u003eOverall, this work reveals a novel class of putative sub-viral entities that appear to be prevalent in the human microbiome. The Obelisks' distinct structures, coding properties, and inferred evolutionary dynamics set them apart from classical viroids and other sub-viral entities. Mostly questions remain. What is the nature of their interactions with their hosts? What do Oblins do and what might this have to do with replication strategies? Are they able to actively avoid CRISPR systems or was this a limitation in sampling / sequence analysis sensitvity? Could there be useful and unique molecular functionality discovered by biochemically characterizing these or other sub-viral entities?\u003c/p\u003e\n\u003cp\u003eRegardless of whether there is wet-lab follow-up, this is precisely the kind of discovery that gets me excited about the era of big genomics data and the power of creative computational bio-prospecting. Here instead of reporting an incrementally better single-cell clustering algorithm, the authors instead reveal new branches of the tree of life.\u003c/p\u003e"])</script><script>self.__next_f.push([1,"14:T4bd9,"])</script><script>self.__next_f.push([1,"\u003cp\u003e\u003cimg src=\"/images/posts/dalle_files/firstdisplay.png\" alt=\"png\"\u003e\u003c/p\u003e\n\u003cp\u003eI wanted to explore the DALL-E 2 diffusion model API along with combinatorial generation algorithms and visualization techniques to create a semi-random collage of latent space manipulations of American Gothic. This experiment involved leveraging both the DALL-E 2 image synthesis capabilities and the GPT-3 language model for style prompt generation, creating a multi-stage generative pipeline. The implementation demonstrates inpainting techniques through masked image editing, where specific spatial regions are reconstructed based on textual conditioning. While developing this computational approach, I utilized ChatGPT for matplotlib visualization assistance, adding a recursive layer of generative model interaction to the creative process. Next, I plan to explore the Whisper automatic speech recognition model from OpenAI.\u003c/p\u003e\n\n\u003ch3\u003eImport Necessary Libaries and Define a Few Helper Functions\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e os\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e openai\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e itertools\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e random\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e PIL \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Image\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e requests\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e uuid\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e os\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e PIL \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Image\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e matplotlib.pyplot \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e plt\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e np\nopenai.api_key =  os.environ[\u003cspan class=\"hljs-string\"\u003e\"OPENAI_API_KEY\"\u003c/span\u003e]\nopenai.Model.\u003cspan class=\"hljs-built_in\"\u003elist\u003c/span\u003e()\n\u003cspan class=\"hljs-comment\"\u003e# Functions\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eask_gpt\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eprompt\u003c/span\u003e):\n    response = openai.Completion.create(\n        engine=\u003cspan class=\"hljs-string\"\u003e\"text-davinci-003\"\u003c/span\u003e,  \u003cspan class=\"hljs-comment\"\u003e# use the latest model available to you\u003c/span\u003e\n        prompt=prompt,\n        max_tokens=\u003cspan class=\"hljs-number\"\u003e200\u003c/span\u003e, \n    )\n    output_text_parsed = response.choices[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].text.strip()\n    \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(output_text_parsed)\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e response\n\u003cspan class=\"hljs-comment\"\u003e# make a uniqueish string to label images as they are generated\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003egenerate_uniqueish_string\u003c/span\u003e():\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003estr\u003c/span\u003e(uuid.uuid4())[:\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e]\n\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eprocess_dalle_images\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eresponse, filename, image_dir, i, \u003cspan class=\"hljs-built_in\"\u003ehash\u003c/span\u003e = \u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e\u003c/span\u003e):\n    \u003cspan class=\"hljs-comment\"\u003e# save the images\u003c/span\u003e\n    uid = generate_uniqueish_string()\n    urls = [datum[\u003cspan class=\"hljs-string\"\u003e\"url\"\u003c/span\u003e] \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e datum \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e response[\u003cspan class=\"hljs-string\"\u003e\"data\"\u003c/span\u003e]]  \u003cspan class=\"hljs-comment\"\u003e# extract URLs\u003c/span\u003e\n    images = [requests.get(url).content \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e url \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e urls]  \u003cspan class=\"hljs-comment\"\u003e# download images\u003c/span\u003e\n    image_names = [\u003cspan class=\"hljs-string\"\u003ef\"\u003cspan class=\"hljs-subst\"\u003e{filename}\u003c/span\u003e_\u003cspan class=\"hljs-subst\"\u003e{i + \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e}\u003c/span\u003e_\u003cspan class=\"hljs-subst\"\u003e{uid}\u003c/span\u003e.png\"\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e j \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-built_in\"\u003elen\u003c/span\u003e(images))]  \u003cspan class=\"hljs-comment\"\u003e# create names\u003c/span\u003e\n    filepaths = [os.path.join(image_dir, name) \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e name \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e image_names]  \u003cspan class=\"hljs-comment\"\u003e# create filepaths\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e image, filepath \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003ezip\u003c/span\u003e(images, filepaths):  \u003cspan class=\"hljs-comment\"\u003e# loop through the variations\u003c/span\u003e\n        \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003eopen\u003c/span\u003e(filepath, \u003cspan class=\"hljs-string\"\u003e\"wb\"\u003c/span\u003e) \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e image_file:  \u003cspan class=\"hljs-comment\"\u003e# open the file\u003c/span\u003e\n            image_file.write(image)  \u003cspan class=\"hljs-comment\"\u003e# write the image to the file\u003c/span\u003e\n\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e filepaths\n\u003cspan class=\"hljs-comment\"\u003e# set a directory to save DALL·E images to\u003c/span\u003e\nimage_dir_name = \u003cspan class=\"hljs-string\"\u003e\"images\"\u003c/span\u003e\nimage_dir = os.path.join(os.curdir, image_dir_name)\n\n\u003cspan class=\"hljs-comment\"\u003e# create the directory if it doesn't yet exist\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003enot\u003c/span\u003e os.path.isdir(image_dir):\n    os.mkdir(image_dir)\n\n\u003cspan class=\"hljs-comment\"\u003e# print the directory to save to\u003c/span\u003e\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003ef\"\u003cspan class=\"hljs-subst\"\u003e{image_dir=}\u003c/span\u003e\"\u003c/span\u003e)\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003etop_half_mask\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003ewidth, height, mask_dir, mask_name\u003c/span\u003e):\n    mask = Image.new(\u003cspan class=\"hljs-string\"\u003e\"RGBA\"\u003c/span\u003e, (width, height), (\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e))\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e x \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(width):\n        \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e y \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(height // \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e):\n            mask.putpixel((x, y), (\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e))\n    mask_filepath = os.path.join(mask_dir, mask_name)\n    mask.save(mask_filepath)\n\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003ebottom_half_mask\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003ewidth, height, mask_dir, mask_name\u003c/span\u003e):\n    mask = Image.new(\u003cspan class=\"hljs-string\"\u003e\"RGBA\"\u003c/span\u003e, (width, height), (\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e))\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e x \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(width):\n        \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e y \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(height // \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, height):\n            mask.putpixel((x, y), (\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e))\n    mask_filepath = os.path.join(mask_dir, mask_name)\n    mask.save(mask_filepath)\n\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eleft_half_mask\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003ewidth, height, mask_dir, mask_name\u003c/span\u003e):\n    mask = Image.new(\u003cspan class=\"hljs-string\"\u003e\"RGBA\"\u003c/span\u003e, (width, height), (\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e))\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e x \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(width // \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e):\n        \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e y \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(height):\n            mask.putpixel((x, y), (\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e))\n    mask_filepath = os.path.join(mask_dir, mask_name)\n    mask.save(mask_filepath)\n\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eright_half_mask\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003ewidth, height, mask_dir, mask_name\u003c/span\u003e):\n    mask = Image.new(\u003cspan class=\"hljs-string\"\u003e\"RGBA\"\u003c/span\u003e, (width, height), (\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e))\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e x \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(width // \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, width):\n        \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e y \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(height):\n            mask.putpixel((x, y), (\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e))\n    mask_filepath = os.path.join(mask_dir, mask_name)\n    mask.save(mask_filepath)\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003eimage_dir='./images'\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eShow Image we are working with\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003eamerican_gothic = \u003cspan class=\"hljs-string\"\u003e\"images/American_Gothic_Square.png\"\u003c/span\u003e\nim = Image.\u003cspan class=\"hljs-built_in\"\u003eopen\u003c/span\u003e(american_gothic)\ndisplay(im)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/posts/dalle_files/dalle_3_0.png\" alt=\"png\"\u003e\u003c/p\u003e\n\u003ch3\u003eLeverage Large Language Models for Style Prompt Generation\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-comment\"\u003e# Prompt engineering for art style enumeration via autoregressive language modeling\u003c/span\u003e\nquestion = \u003cspan class=\"hljs-string\"\u003e\"provide a python list of 15 distinct art styles (i.e. impressionist, cubist, pointlist, photorealistic, japanese wood block print)\"\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e# Join the description and question into a single string\u003c/span\u003e\nprompt = \u003cspan class=\"hljs-string\"\u003ef\"\u003cspan class=\"hljs-subst\"\u003e{question}\u003c/span\u003e\"\u003c/span\u003e\ngpt_output = ask_gpt(prompt)\n\u003cspan class=\"hljs-comment\"\u003e# Parse the output\u003c/span\u003e\nart_styles_string = gpt_output.choices[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e][\u003cspan class=\"hljs-string\"\u003e'text'\u003c/span\u003e]\nart_styles = [line.split(\u003cspan class=\"hljs-string\"\u003e'. '\u003c/span\u003e)[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e] \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e line \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e art_styles_string.split(\u003cspan class=\"hljs-string\"\u003e'\\n'\u003c/span\u003e) \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e line]\n\u003cspan class=\"hljs-comment\"\u003e# choose the length of combinations you want, for example 2\u003c/span\u003e\nlength_of_combinations = \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e\nstyle_combinations = \u003cspan class=\"hljs-built_in\"\u003elist\u003c/span\u003e(itertools.combinations(art_styles, length_of_combinations))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003e1. Impressionism \n2. Cubism \n3. Pointillism \n4. Photorealism \n5. Japanese Wood Block Print \n6. Expressionism \n7. Constructivism \n8. Abstract Expressionism \n9. Surrealism \n10. Baroque \n11. Realism \n12. Neo-Impressionism \n13. Art Deco \n14. Cubo-Futurism \n15. Op Art\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-comment\"\u003e# Format the GPT output for Dalle prompt\u003c/span\u003e\nformatted_strings = []\n\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e combination \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e style_combinations:\n    style_1, style_2 = combination\n    formatted_string = \u003cspan class=\"hljs-string\"\u003ef\"in the style of \u003cspan class=\"hljs-subst\"\u003e{style_1}\u003c/span\u003e and \u003cspan class=\"hljs-subst\"\u003e{style_2}\u003c/span\u003e\"\u003c/span\u003e\n    formatted_strings.append(formatted_string)\n\u003cspan class=\"hljs-comment\"\u003e# TODO would be better to print at random from the list to actually show\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e string \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e formatted_strings[:\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e]:\n    \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(string)\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003ein the style of Impressionism  and Cubism .\nin the style of Impressionism  and Pointillism .\nin the style of Pointillism  and Surrealism .\nin the style of Cubism  and Baroque .\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eCreate Masks\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003emask_dir = \u003cspan class=\"hljs-string\"\u003e\"images/masks\"\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e# create the directory if it doesn't yet exist\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003enot\u003c/span\u003e os.path.isdir(mask_dir):\n    os.mkdir(mask_dir)\n\u003cspan class=\"hljs-comment\"\u003e# print the directory to save to\u003c/span\u003e\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003ef\"\u003cspan class=\"hljs-subst\"\u003e{mask_dir=}\u003c/span\u003e\"\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# TODO ask what are the actual image sizes \u003c/span\u003e\nwidth = \u003cspan class=\"hljs-number\"\u003e574\u003c/span\u003e\nheight = \u003cspan class=\"hljs-number\"\u003e574\u003c/span\u003e\n\nmask_dir = \u003cspan class=\"hljs-string\"\u003e\"./masks\"\u003c/span\u003e\nos.makedirs(mask_dir, exist_ok=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e)  \u003cspan class=\"hljs-comment\"\u003e# ensure the directory exists\u003c/span\u003e\ntop_half_mask(width, height, mask_dir, \u003cspan class=\"hljs-string\"\u003e\"top_half_mask.png\"\u003c/span\u003e)\nbottom_half_mask(width, height, mask_dir, \u003cspan class=\"hljs-string\"\u003e\"bottom_half_mask.png\"\u003c/span\u003e)\nleft_half_mask(width, height, mask_dir, \u003cspan class=\"hljs-string\"\u003e\"left_half_mask.png\"\u003c/span\u003e)\nright_half_mask(width, height, mask_dir, \u003cspan class=\"hljs-string\"\u003e\"right_half_mask.png\"\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# specify edit images dir\u003c/span\u003e\nedit_image_dir = os.path.join(\u003cspan class=\"hljs-string\"\u003e\"images\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"edits\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode\u003emask_dir='images/masks'\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003eos.makedirs(\u003cspan class=\"hljs-string\"\u003ef\"\u003cspan class=\"hljs-subst\"\u003e{edit_image_dir}\u003c/span\u003e\"\u003c/span\u003e, exist_ok=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eExecute DALL-E 2 Inpainting with Stochastic Mask Selection and Style Conditioning\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-comment\"\u003e# \u003cspan class=\"hljs-doctag\"\u003eTODO:\u003c/span\u003e implement metadata embedding for tracking conditioning parameters in generated samples\u003c/span\u003e\n\n\u003cspan class=\"hljs-comment\"\u003e# Specify the directory\u003c/span\u003e\nmask_dir = \u003cspan class=\"hljs-string\"\u003e\"./masks/\"\u003c/span\u003e\nnum_iterations = \u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e  \u003cspan class=\"hljs-comment\"\u003e# specify the number of iterations\u003c/span\u003e\n\n\u003cspan class=\"hljs-comment\"\u003e# Get the list of all masks in the directory\u003c/span\u003e\nmasks = [f \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e f \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e os.listdir(mask_dir) \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e f.endswith(\u003cspan class=\"hljs-string\"\u003e'.png'\u003c/span\u003e)]\n\n\u003cspan class=\"hljs-comment\"\u003e# Iterate for the number of specified iterations\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e i \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(num_iterations):\n    \u003cspan class=\"hljs-comment\"\u003e# Select a random mask\u003c/span\u003e\n    selected_mask = random.choice(masks)\n    \u003cspan class=\"hljs-comment\"\u003e# Get the full file path of the selected mask\u003c/span\u003e\n    mask_filepath = os.path.join(mask_dir, selected_mask)\n\n    \u003cspan class=\"hljs-comment\"\u003e# Select a random style combination\u003c/span\u003e\n    selected_prompt = random.choice(formatted_strings)\n\n    \u003cspan class=\"hljs-comment\"\u003e# Execute conditional image generation via masked inpainting\u003c/span\u003e\n    edit_response = openai.Image.create_edit(\n        image=\u003cspan class=\"hljs-built_in\"\u003eopen\u003c/span\u003e(american_gothic, \u003cspan class=\"hljs-string\"\u003e\"rb\"\u003c/span\u003e),  \u003cspan class=\"hljs-comment\"\u003e# source image for conditioning\u003c/span\u003e\n        mask=\u003cspan class=\"hljs-built_in\"\u003eopen\u003c/span\u003e(mask_filepath, \u003cspan class=\"hljs-string\"\u003e\"rb\"\u003c/span\u003e),  \u003cspan class=\"hljs-comment\"\u003e# spatial mask for inpainting region\u003c/span\u003e\n        prompt=selected_prompt,  \u003cspan class=\"hljs-comment\"\u003e# textual conditioning for style transfer\u003c/span\u003e\n        n=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e,  \u003cspan class=\"hljs-comment\"\u003e# number of samples from posterior distribution\u003c/span\u003e\n        size=\u003cspan class=\"hljs-string\"\u003e\"512x512\"\u003c/span\u003e,  \u003cspan class=\"hljs-comment\"\u003e# output resolution\u003c/span\u003e\n        response_format=\u003cspan class=\"hljs-string\"\u003e\"url\"\u003c/span\u003e,\n    )\n    \n    \u003cspan class=\"hljs-comment\"\u003e# print response for prototype / debug\u003c/span\u003e\n    \u003cspan class=\"hljs-comment\"\u003e# print(edit_response)\u003c/span\u003e\n    edit_filepaths = process_dalle_images(edit_response, \u003cspan class=\"hljs-string\"\u003e\"edits\"\u003c/span\u003e, edit_image_dir, i, \u003cspan class=\"hljs-built_in\"\u003ehash\u003c/span\u003e = \u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e)\n\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3\u003eVisualization of Generated Sample Distribution via Grid Assembly\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-comment\"\u003e# Specify the directory\u003c/span\u003e\nimage_directory = \u003cspan class=\"hljs-string\"\u003e\"images/edits/\"\u003c/span\u003e\nimage_files = [f \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e f \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e os.listdir(image_directory) \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e f.endswith(\u003cspan class=\"hljs-string\"\u003e'.png'\u003c/span\u003e)]\n\u003cspan class=\"hljs-comment\"\u003e# shuffle image file order to get different images in the plot\u003c/span\u003e\nimage_files = np.random.permutation(image_files)\n\u003cspan class=\"hljs-comment\"\u003e# Load all the images\u003c/span\u003e\nimages = [Image.\u003cspan class=\"hljs-built_in\"\u003eopen\u003c/span\u003e(image_directory + f) \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e f \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e image_files]\n\u003cspan class=\"hljs-comment\"\u003e# Ensure sufficient samples for statistical visualization through repetition\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003ewhile\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003elen\u003c/span\u003e(images) \u0026#x3C; \u003cspan class=\"hljs-number\"\u003e100\u003c/span\u003e:\n    images *= \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e\n\n\u003cspan class=\"hljs-comment\"\u003e# Only take the first 100 images\u003c/span\u003e\nimages = images[:\u003cspan class=\"hljs-number\"\u003e100\u003c/span\u003e]\n\n\u003cspan class=\"hljs-comment\"\u003e# Create a 10x10 visualization grid for sample distribution analysis\u003c/span\u003e\nfig, axes = plt.subplots(\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, figsize=(\u003cspan class=\"hljs-number\"\u003e18\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e18\u003c/span\u003e))\n\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e i \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e):\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e j \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e):\n        \u003cspan class=\"hljs-comment\"\u003e# Get the image\u003c/span\u003e\n        img = images[i * \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e + j]\n\n        \u003cspan class=\"hljs-comment\"\u003e# Remove the axes for each subplot\u003c/span\u003e\n        axes[i, j].axis(\u003cspan class=\"hljs-string\"\u003e'off'\u003c/span\u003e)\n\n        \u003cspan class=\"hljs-comment\"\u003e# Display the image on the subplot\u003c/span\u003e\n        axes[i, j].imshow(np.array(img), aspect=\u003cspan class=\"hljs-string\"\u003e'auto'\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# Adjust the space between the subplots\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e# Negative values for wspace and hspace will make the images overlap\u003c/span\u003e\nplt.subplots_adjust(wspace=-\u003cspan class=\"hljs-number\"\u003e0.05\u003c/span\u003e, hspace=-\u003cspan class=\"hljs-number\"\u003e0.05\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# Show the plot\u003c/span\u003e\nplt.show()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/images/posts/dalle_files/dalle_13_0.png\" alt=\"png\"\u003e\u003c/p\u003e"])</script><script>self.__next_f.push([1,"5:[\"$\",\"main\",null,{\"className\":\"min-h-screen bg-background\",\"children\":[\"$\",\"$Le\",null,{\"leftSide\":[\"$\",\"$Lf\",null,{\"aboutContent\":{\"slug\":\"about\",\"content\":\"\u003cp\u003e\u003cstrong\u003eCurrently\u003c/strong\u003e\\nI'm a systems biologist using ML to design better RNA therapeutics.\u003c/p\u003e\\n\u003cp\u003eI earned my PhD at Stanford in the Quake lab, where I studied the generation and maintenance of diversity in the human immune system.\u003c/p\u003e\\n\u003cp\u003e\u003cstrong\u003eSome other interests:\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003esequencing everything\u003c/p\u003e\\n\u003cp\u003esculpting biomes using gene drives\u003c/p\u003e\\n\u003cp\u003eproducing music\u003c/p\u003e\",\"title\":\"\",\"date\":\"$undefined\",\"excerpt\":\"About me\",\"category\":\"$undefined\",\"tags\":\"$undefined\",\"permalink\":\"/\",\"author_profile\":true,\"redirect_from\":[\"/about/\",\"/about.html\"]}}],\"rightSide\":[\"$\",\"$L10\",null,{\"posts\":[{\"slug\":\"2025-06-14-pedalbored\",\"content\":\"$11\",\"title\":\"PedalBored: Distorting Lyrics Like Guitar Pedals Distort Sound\",\"date\":\"$D2025-06-14T00:00:00.000Z\",\"excerpt\":\"$undefined\",\"category\":\"$undefined\",\"tags\":[\"transformer-models\",\"semantic-drift\",\"lyrical-analysis\",\"computational-linguistics\",\"machine-translation\",\"python\"],\"layout\":\"post\",\"categories\":[\"natural-language-processing\",\"computational-creativity\",\"music-informatics\"]},{\"slug\":\"2024-11-19-minimal-latex-job-description-template\",\"content\":\"$12\",\"title\":\"A Minimal LaTeX Job Description Template\",\"date\":\"$D2024-11-19T00:00:00.000Z\",\"excerpt\":\"$undefined\",\"category\":\"$undefined\",\"tags\":[\"latex\",\"job-description\",\"template\",\"documentation\"],\"layout\":\"post\",\"categories\":[\"latex\",\"templates\"]},{\"slug\":\"2024-03-11-rna-obelisks\",\"content\":\"$13\",\"title\":\"RNA Obelisks\",\"date\":\"$D2024-03-11T00:00:00.000Z\",\"excerpt\":\"$undefined\",\"category\":\"$undefined\",\"tags\":[\"virology\",\"genomics\",\"rna-biology\",\"computational-virology\",\"subviral-entities\",\"microbiome\",\"phylogenomics\",\"structural-biology\"],\"permalink\":\"/posts/2024/03/obelisks\",\"excerpt_separator\":\"\u003c!--more--\u003e\",\"always_allow_html\":true,\"toc\":true},{\"slug\":\"2023-10-24-cover_letter\",\"content\":\"\u003cp\u003e\u003cimg src=\\\"/images/posts/latex/manuscript_submission_cover_letter_overleaf.png\\\" alt=\\\"png\\\"\u003e\u003c/p\u003e\\n\u003cp\u003eI was writing a cover letter for a journal submission and got tired of manually formatting everything each time. So I made a LaTeX template to automate the process. It handles all the standard formatting and lets you just fill in the details.\u003c/p\u003e\\n\\n\u003cp\u003eThe template takes care of the layout, spacing, and professional formatting automatically. You just need to update a few variables at the top of the document with your information and the journal details, and it generates a properly formatted cover letter.\u003c/p\u003e\\n\u003cp\u003eI've put it up on \u003ca href=\\\"https://github.com/michael-swift/JournalCoverLetter\\\"\u003eGitHub\u003c/a\u003e and made it available as a template on \u003ca href=\\\"https://www.overleaf.com/latex/templates/journal-submission-cover-letter/vsvmwwszmdtn\\\"\u003eOverleaf\u003c/a\u003e so anyone can use it.\u003c/p\u003e\",\"title\":\"Cover Letter LaTeX Template\",\"date\":\"$D2023-11-20T00:00:00.000Z\",\"excerpt\":\"$undefined\",\"category\":\"$undefined\",\"tags\":[\"document-generation\",\"typesetting-systems\",\"manuscript-preparation\",\"template-engineering\",\"scholarly-communication\"],\"permalink\":\"/posts/2023/10/cover_letter\",\"categories\":[\"Document-Automation\",\"Academic-Publishing\"],\"header\":{\"og_image\":\"/images/posts/latex/fake_university_seal.png\"}},{\"slug\":\"2023-05-24-dalle\",\"content\":\"$14\",\"title\":\"DALL-E and a Combinatoric Collage: Generative Image Models\",\"date\":\"$D2023-05-26T00:00:00.000Z\",\"excerpt\":\"$undefined\",\"category\":\"$undefined\",\"tags\":[\"computer-vision\",\"generative-modeling\",\"multimodal-ai\",\"image-synthesis\",\"diffusion-models\",\"neural-networks\",\"deep-learning\"],\"permalink\":\"/posts/2023/05/dalle\",\"excerpt_separator\":\"\u003c!--more--\u003e\",\"always_allow_html\":true,\"toc\":true,\"header\":{\"og_image\":\"/images/posts/dalle_files/edits_8_9c190010.png\"},\"categories\":[\"computer-vision\",\"generative-ai\"]}],\"scienceProjects\":[{\"slug\":\"project-1\",\"content\":\"\u003cimg src=\\\"/images/tabula_bursa_schematic.png\\\" alt=\\\"Tabula Bursa Schematic\\\"\u003e\\n\u003cp\u003eBy sampling B cells from multiple hard-to-study organs within the same individual, Ivana Cvijovic and I generated the first systems-level perspective of the human antibody system. Most immune-monitoring efforts focus on the peripheral blood because it is non-invasive. Our study compares as many as 5 organs per donor, which allows systematic insights into the dynamics of long-term antibody memory in Humans and informs non-invasive immune monitoring.\u003c/p\u003e\\n\u003cp\u003eKey findings:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003eLong-term antibody memory emerges uniformly throughout the immune response\u003c/li\u003e\\n\u003cli\u003eProliferative antibody-secreting cells uniquely circulate among multiple tissues\u003c/li\u003e\\n\u003cli\u003eImmune-monitoring via the peripheral blood has key sampling biases and limitations\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003e\u003ca href=\\\"https://www.biorxiv.org/content/10.1101/2023.11.27.568934v1.full.pdf\\\"\u003eRead the full paper\u003c/a\u003e\u003c/p\u003e\",\"title\":\"Mapping the Statistics of the Human B cell system\",\"date\":\"2025\",\"excerpt\":\"A systems-level view of B cells by sampling multiple hard-to-study organs within the same individual.\",\"category\":\"Systems Biology\",\"tags\":\"$undefined\",\"link\":\"https://www.pnas.org/doi/10.1073/pnas.2406474122\",\"collection\":\"science\"},{\"slug\":\"project-2\",\"content\":\"\u003cimg src=\\\"/images/bcell_schematic.png\\\" alt=\\\"B Cell Schematic\\\"\u003e\\n\u003cp\u003eThis study investigates how cells integrate external signals with their intrinsic state during reprogramming, using human B cells as a model system.\u003c/p\u003e\\n\u003cp\u003eKey findings:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003eIntrinsic cellular states significantly influence reprogramming outcomes\u003c/li\u003e\\n\u003cli\u003eReprogrammed cell populations show high diversity in final states\u003c/li\u003e\\n\u003cli\u003eCells from the same lineage (clones) often adopt similar fates, indicating the importance of initial cell state\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cimg src=\\\"/images/lineage_tracing_measurement.png\\\" alt=\\\"Lineage Graph\\\"\u003e\\n\u003cp\u003eThese results have important implications for cell-based therapies and tissue engineering. Intrinsic heterogeneity in the input cells should be understood and harnessed for better outcomes.\u003c/p\u003e\\n\u003cp\u003e\u003ca href=\\\"https://www.life-science-alliance.org/content/lsa/6/3/e202201792.full.pdf\\\"\u003eRead the full paper\u003c/a\u003e | \u003ca href=\\\"https://doi.org/10.6084/m9.figshare.26348788\\\"\u003eDownload processed data\u003c/a\u003e\u003c/p\u003e\",\"title\":\"Leveraging lineage tracing to understand cell reprogramming\",\"date\":\"2023\",\"excerpt\":\"How cells integrate external signals with their intrinsic state during reprogramming, using human B cells as a model system.\",\"category\":\"Cell Biology\",\"tags\":\"$undefined\",\"link\":\"https://www.life-science-alliance.org/content/lsa/6/3/e202201792.full.pdf\",\"collection\":\"science\"},{\"slug\":\"project-3\",\"content\":\"\u003cimg src=\\\"/images/reduced_ts_figure.png\\\" alt=\\\"Reduced TS Figure\\\"\u003e\\n\u003cp\u003eI have been key contributor to the Tabula Sapiens Consortium. I helped create a multi-organ, single-cell transcriptomic atlas of humans. This atlas serves as a valuable resource for training foundation models of biology and understanding the molecular basis of diseases.\u003c/p\u003e\\n\u003cp\u003eMy contributions include:\u003c/p\u003e\\n\u003cul\u003e\\n\u003cli\u003eProcuring organs\u003c/li\u003e\\n\u003cli\u003eProcessing tissues into single-cell suspensions\u003c/li\u003e\\n\u003cli\u003ePreparing sequencing libraries\u003c/li\u003e\\n\u003cli\u003eAnalyzing vast datasets with complex and varied forms of technical noise\u003c/li\u003e\\n\u003c/ul\u003e\\n\u003cp\u003eResearch focus:\\nAnalyzing immune cells across tissues to gain new insights into this complex system's function and regulation within the context of the broader human atlas.\u003c/p\u003e\\n\u003cp\u003e\u003ca href=\\\"https://www.science.org/doi/10.1126/science.abl4896\\\"\u003eRead the full paper\u003c/a\u003e\u003c/p\u003e\",\"title\":\"Creating the datasets to enable Molecular Medicine\",\"date\":\"2022\",\"excerpt\":\"I have been a key contributor to the Tabula Sapiens Consortium. Massive single-cell molecular datasets like this have been instrumental cell modeling efforts.\",\"category\":\"Single Cell Transcriptomics\",\"tags\":\"$undefined\",\"link\":\"https://tabula-sapiens.sf.czbiohub.org/\",\"collection\":\"science\"},{\"slug\":\"sequencing\",\"content\":\"\u003cul\u003e\\n\u003cli\u003e\u003ca href=\\\"https://aseq.substack.com/\\\"\u003eA-seq\u003c/a\u003e - sequencing technologies and associated approaches including diagnositics and tools\u003c/li\u003e\\n\u003cli\u003e\u003ca href=\\\"https://biotechbio.substack.com/\\\"\u003eBiotechBio\u003c/a\u003e - someone at the forefront of AI and Bio\u003c/li\u003e\\n\u003cli\u003e\u003ca href=\\\"https://substack.com/@billyhb\\\"\u003eBilly's Newsletter\u003c/a\u003e - cool guy\u003c/li\u003e\\n\u003cli\u003e\u003ca href=\\\"https://www.nxn.se/\\\"\u003eNxN\u003c/a\u003e - great for single cell rna seq amongst other topics\u003c/li\u003e\\n\u003cli\u003e\u003ca href=\\\"https://www.owlposting.com/\\\"\u003eOwl Posting\u003c/a\u003e - ML / Bio posting\u003c/li\u003e\\n\u003c/ul\u003e\",\"title\":\"\",\"date\":\"$undefined\",\"excerpt\":\"Some good blogs I've stumbled across over the years\",\"category\":\"$undefined\",\"tags\":\"$undefined\",\"disable_link\":true,\"collection\":\"science\",\"layout\":\"single\"}],\"coverImages\":[{\"src\":\"/covers/3d_IgG1.png\",\"alt\":\"3d IgG1\",\"width\":1920,\"height\":1080},{\"src\":\"/covers/96_well_technical.png\",\"alt\":\"96 Well Technical\",\"width\":1920,\"height\":1080},{\"src\":\"/covers/RibbonModel-crJaneRichardson-Lede-2048x1152.webp\",\"alt\":\"RibbonModel CrJaneRichardson Lede 2048x1152\",\"width\":1920,\"height\":1080},{\"src\":\"/covers/Waddingtons-1957-depiction-of-his-epigenetic-landscape-reprinted-with-permission.png\",\"alt\":\"Waddingtons 1957 Depiction Of His Epigenetic Landscape Reprinted With Permission\",\"width\":1920,\"height\":1080},{\"src\":\"/covers/clepsine.png\",\"alt\":\"Clepsine\",\"width\":1920,\"height\":1080},{\"src\":\"/covers/yamanaka_factors_stylized.png\",\"alt\":\"Yamanaka Factors Stylized\",\"width\":1920,\"height\":1080}]}]}]}]\n"])</script><script>self.__next_f.push([1,"a:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n7:null\n"])</script><script>self.__next_f.push([1,"8:null\nc:[[\"$\",\"title\",\"0\",{\"children\":\"Michael Swift\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Founding Research Scientist @ Kerna Labs\"}],[\"$\",\"link\",\"2\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script></body></html>